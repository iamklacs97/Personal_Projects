{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXfvihT3DzSF"
      },
      "source": [
        "# Importing packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dp3iL5aUECDL"
      },
      "outputs": [],
      "source": [
        "# utility packages\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# tensorflow \n",
        "import tensorflow as tf\n",
        "\n",
        "# random package\n",
        "import random \n",
        "\n",
        "# warnings \n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZON9yN0ESBI"
      },
      "source": [
        "### Checking for GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pQjQfwOE7CJ",
        "outputId": "f832bbe7-e573-4724-bae8-efdc762a99c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':  \n",
        "  print(f'No GPU was found.')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64hMBWIjE7fa"
      },
      "source": [
        "### Loading the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g697hdknFCMm"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42QBUpOaFGZn",
        "outputId": "b63a1d3b-d66e-42c3-faea-980dcb75004c"
      },
      "outputs": [],
      "source": [
        "### unzipping the mnist dataset \n",
        "\n",
        "(xTrain,yTrainLabel),(xTest,yTestLabel) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5vSZwC8KC6G"
      },
      "source": [
        "### Manipulation the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BFNNt2RtFQrt"
      },
      "outputs": [],
      "source": [
        "### One-hot encoding the training and test labels\n",
        "\n",
        "classes = 10 # 0-9 categories for the num_classes parameter\n",
        "\n",
        "# training\n",
        "yTrainCat = tf.keras.utils.to_categorical(y = yTrainLabel, num_classes = classes, dtype = 'float32')\n",
        "\n",
        "# testing\n",
        "yTestCat = tf.keras.utils.to_categorical(y = yTestLabel, num_classes = classes, dtype = 'float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRZlRICcGTRY",
        "outputId": "11c26d3d-67d6-43f3-e36f-6a966de9c827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape: (60000, 28, 28) | Training dataset datatype: uint8 \n",
            "Testing dataset shape: (10000, 28, 28) | Testing dataset datatype: uint8\n",
            "Training dataset pixel range: (0, 255) | Testing dataset pixel range: (0, 255)\n"
          ]
        }
      ],
      "source": [
        "### Shape and datatype of MNIST dataset\n",
        "\n",
        "print(f'Training dataset shape: {xTrain.shape} | Training dataset datatype: {xTrain.dtype} \\nTesting dataset shape: {xTest.shape} | Testing dataset datatype: {xTrain.dtype}')\n",
        "print(f'Training dataset pixel range: {(np.min(xTrain),np.max(xTrain))} | Testing dataset pixel range: {(np.min(xTest),np.max(xTest))}' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HbyMhI6JtzX"
      },
      "source": [
        "**Need to reshape, change the datatype, and min_max scale the tensor values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OC_g8N5OK0Ao"
      },
      "outputs": [],
      "source": [
        "### Manipulate the training and testing input\n",
        "\n",
        "xTrain = (xTrain/255).astype('float32') # 0-1 scaled, datatype is now a float\n",
        "xTest = (xTest/255).astype('float32') # 0-1 scaled, datatype is now a float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kd4V3LGLuHl"
      },
      "source": [
        "### Build and establish the model\n",
        "The upper restriciton on the number of params: 200,000. I will initialize a function api model using keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4trvpgZYMM0b"
      },
      "outputs": [],
      "source": [
        "### Model ### --- layer adjustments\n",
        "\n",
        "#creating lists for column names \n",
        "model_names = []\n",
        "first_layer_nodes = []\n",
        "second_layer_nodes = []\n",
        "first_layer_activation = []\n",
        "second_layer_activation = []\n",
        "output_layer_activation = []\n",
        "training_loss = []\n",
        "training_accuracy = []\n",
        "validation_loss = []\n",
        "validation_accuracy = []\n",
        "batch_size = [] \n",
        "num_of_epochs = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "optimizer_function = []\n",
        "loss_function = []\n",
        "\n",
        "def model_builder1(training_dataset = xTrain, \n",
        "                  training_labels = yTrainCat, \n",
        "                  testing_dataset = xTest, \n",
        "                  testing_labels = yTestCat):\n",
        "  \n",
        "  ### ----- Local Variables ----- ###\n",
        "  counter = 0\n",
        "  firstActive = 'relu'\n",
        "  secondActive = 'relu'\n",
        "  outputActive = 'sigmoid'\n",
        "  firstLayerNodes = [150,200] # number of nodes in first layer list\n",
        "  secondLayerNodes = [30,50]  # number of nodes in second layer list\n",
        "\n",
        "  ### ----- Creating the full-dense network ----- ###\n",
        "\n",
        "  for i in firstLayerNodes: # will iterate through first layer nodes\n",
        "    for j in secondLayerNodes: # iterate through second layer nodes\n",
        "      counter += 1\n",
        "      inputLayer = tf.keras.Input(shape = (28,28), name = 'input_layer')\n",
        "      flattenLayer = tf.keras.layers.Flatten(name = 'flatten_layer')(inputLayer)\n",
        "      denseLayer1 = tf.keras.layers.Dense(units = i, activation = firstActive, name = 'dense_layer_1')(flattenLayer)\n",
        "      denseLayer2 = tf.keras.layers.Dense(units = j, activation = secondActive, name = 'dense_layer_2')(denseLayer1)\n",
        "      outputLayer = tf.keras.layers.Dense(units = 10, activation = outputActive, name = 'output_layer')(denseLayer2)\n",
        "      \n",
        "      # appending all hyperparameters into lists\n",
        "      first_layer_nodes.append(i) # append number of first layer nodes \n",
        "      second_layer_nodes.append(j) # append number of second layer nodes\n",
        "      first_layer_activation.append(firstActive) # append first layer activation function\n",
        "      second_layer_activation.append(secondActive) # append second layer activation function\n",
        "      output_layer_activation.append(outputActive) # append output layer activation function\n",
        "\n",
        "      modelName = f'NN_Model{str(counter)}' # generating model names to put into list\n",
        "      model_names.append(modelName) # appending name to model_names list\n",
        "\n",
        "      model = tf.keras.Model(inputs = inputLayer, outputs = outputLayer, name = modelName)\n",
        "\n",
        "      ### ----- Model Parameters ----- ###\n",
        "\n",
        "      optFunction = tf.keras.optimizers.Adam(learning_rate =  0.025) # optimizer function\n",
        "      lossFunction = tf.keras.losses.BinaryCrossentropy() # loss function\n",
        "\n",
        "      optimizer_function.append(str(optFunction)) # append optimizer function\n",
        "      loss_function.append(str(lossFunction)) # append loss function\n",
        "\n",
        "      ### ----- Compiler ----- ###\n",
        "      model.compile(\n",
        "        optimizer = optFunction,\n",
        "        loss = lossFunction,\n",
        "        metrics = tf.keras.metrics.Accuracy()\n",
        "      )\n",
        "\n",
        "      ##### ----- Fitting the model ----- ###\n",
        "      print(f'first layer: {i}, second layer {j}') \n",
        "\n",
        "      tf.random.set_seed(42)\n",
        "\n",
        "      bSize = 200\n",
        "      epoch = 250\n",
        "      vSplit = 0.1\n",
        "      trainModel = model.fit(\n",
        "          x = xTrain,\n",
        "          y = yTrainCat,\n",
        "          batch_size = bSize,\n",
        "          epochs = epoch,\n",
        "          validation_split = vSplit\n",
        "      )\n",
        "\n",
        "      batch_size.append(bSize) # append batch size\n",
        "      num_of_epochs.append(epoch) # append number of epochs \n",
        "      \n",
        "      ### ----- Results ----- ###\n",
        "      # appending the validation accuracy into the list\n",
        "      training_loss.append(min(trainModel.history['loss'])) # append training loss\n",
        "      training_accuracy.append(max(trainModel.history['accuracy'])) # append training accuracy\n",
        "      validation_loss.append(min(trainModel.history['val_loss'])) # append validation loss\n",
        "      validation_accuracy.append(max(trainModel.history['val_accuracy'])) # append validation accuracy \n",
        "                                  \n",
        "      # appending the test accuracy into the list\n",
        "      finalResults = model.evaluate(xTest,yTestCat)\n",
        "\n",
        "      test_loss.append(finalResults[0]) # append test loss\n",
        "      test_accuracy.append(finalResults[1]) # append test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_builder2(training_dataset = xTrain, \n",
        "                  training_labels = yTrainCat, \n",
        "                  testing_dataset = xTest, \n",
        "                  testing_labels = yTestCat):\n",
        "  \n",
        "  ### ----- Local Variables ----- ###\n",
        "  counter = 4 #starting where model_builder1 left off\n",
        "  firstActive = 'gelu'\n",
        "  secondActive = 'gelu'\n",
        "  outputActive = 'softmax'\n",
        "  firstLayerNodes = [150,200] # number of nodes in first layer list\n",
        "  secondLayerNodes = [30,50]  # number of nodes in second layer list\n",
        "\n",
        "  ### ----- Creating the full-dense network ----- ###\n",
        "\n",
        "  for i in firstLayerNodes: # will iterate through first layer nodes\n",
        "    for j in secondLayerNodes: # iterate through second layer nodes\n",
        "      counter += 1\n",
        "      inputLayer = tf.keras.Input(shape = (28,28), name = 'input_layer')\n",
        "      flattenLayer = tf.keras.layers.Flatten(name = 'flatten_layer')(inputLayer)\n",
        "      denseLayer1 = tf.keras.layers.Dense(units = i, activation = firstActive, name = 'dense_layer_1')(flattenLayer)\n",
        "      denseLayer2 = tf.keras.layers.Dense(units = j, activation = secondActive, name = 'dense_layer_2')(denseLayer1)\n",
        "      outputLayer = tf.keras.layers.Dense(units = 10, activation = outputActive, name = 'output_layer')(denseLayer2)\n",
        "\n",
        "      # appending all hyperparameters into lists\n",
        "      first_layer_nodes.append(i) # append number of first layer nodes \n",
        "      second_layer_nodes.append(j) # append number of second layer nodes\n",
        "      first_layer_activation.append(firstActive) # append first layer activation function\n",
        "      second_layer_activation.append(secondActive) # append second layer activation function\n",
        "      output_layer_activation.append(outputActive) # append output layer activation function\n",
        "\n",
        "      modelName = f'NN_Model{str(counter)}' # generating model names to put into list\n",
        "      model_names.append(modelName) # appending name to model_names list\n",
        "\n",
        "      model = tf.keras.Model(inputs = inputLayer, outputs = outputLayer, name = modelName)\n",
        "\n",
        "      ### ----- Model Parameters ----- ###\n",
        "      if counter%2 == 0: \n",
        "        optFunction = tf.keras.optimizers.Adam(learning_rate =  0.025) # optimizer function\n",
        "        lossFunction = tf.keras.losses.BinaryCrossentropy() # loss function\n",
        "      else:\n",
        "        optFunction = tf.keras.optimizers.SGD(learning_rate =  0.025) # optimizer function\n",
        "        lossFunction = tf.keras.losses.Hinge() # loss function  \n",
        "\n",
        "      optimizer_function.append(str(optFunction)) # append optimizer function\n",
        "      loss_function.append(str(lossFunction)) # append loss function\n",
        "\n",
        "      ### ----- Compiler ----- ###\n",
        "      model.compile(\n",
        "        optimizer = optFunction,\n",
        "        loss = lossFunction,\n",
        "        metrics = tf.keras.metrics.Accuracy()\n",
        "      )\n",
        "\n",
        "      ##### ----- Fitting the model ----- ###\n",
        "      print(f'first layer: {i}, second layer {j}') \n",
        "\n",
        "      tf.random.set_seed(42)\n",
        "\n",
        "      bSize = 200\n",
        "      epoch = 250\n",
        "      vSplit = 0.1\n",
        "      trainModel = model.fit(\n",
        "          x = xTrain,\n",
        "          y = yTrainCat,\n",
        "          batch_size = bSize,\n",
        "          epochs = epoch,\n",
        "          validation_split = vSplit\n",
        "      )\n",
        "\n",
        "      batch_size.append(bSize) # append batch size\n",
        "      num_of_epochs.append(epoch) # append number of epochs \n",
        "      \n",
        "      ### ----- Results ----- ###\n",
        "      # appending the validation accuracy into the list\n",
        "      training_loss.append(min(trainModel.history['loss'])) # append training loss\n",
        "      training_accuracy.append(max(trainModel.history['accuracy'])) # append training accuracy\n",
        "      validation_loss.append(min(trainModel.history['val_loss'])) # append validation loss\n",
        "      validation_accuracy.append(max(trainModel.history['val_accuracy'])) # append validation accuracy \n",
        "                                 \n",
        "      # appending the test accuracy into the list\n",
        "      finalResults = model.evaluate(xTest,yTestCat)\n",
        "\n",
        "      test_loss.append(finalResults[0]) # append test loss\n",
        "      test_accuracy.append(finalResults[1]) # append test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_builder3(training_dataset = xTrain, \n",
        "                  training_labels = yTrainCat, \n",
        "                  testing_dataset = xTest, \n",
        "                  testing_labels = yTestCat):\n",
        "  \n",
        "  ### ----- Local Variables ----- ###\n",
        "  counter = 8 #starting where model_builder2 left off\n",
        "  firstActive = 'elu'\n",
        "  secondActive = 'elu'\n",
        "  outputActive = 'swish'\n",
        "  firstLayerNodes = [150,200] # number of nodes in first layer list\n",
        "  secondLayerNodes = [30,50]  # number of nodes in second layer list\n",
        "\n",
        "  ### ----- Creating the full-dense network ----- ###\n",
        "\n",
        "  for i in firstLayerNodes: # will iterate through first layer nodes\n",
        "    for j in secondLayerNodes: # iterate through second layer nodes\n",
        "      counter += 1\n",
        "      inputLayer = tf.keras.Input(shape = (28,28), name = 'input_layer')\n",
        "      flattenLayer = tf.keras.layers.Flatten(name = 'flatten_layer')(inputLayer)\n",
        "      denseLayer1 = tf.keras.layers.Dense(units = i, activation = firstActive, name = 'dense_layer_1')(flattenLayer)\n",
        "      denseLayer2 = tf.keras.layers.Dense(units = j, activation = secondActive, name = 'dense_layer_2')(denseLayer1)\n",
        "      outputLayer = tf.keras.layers.Dense(units = 10, activation = outputActive, name = 'output_layer')(denseLayer2)\n",
        "\n",
        "      # appending all hyperparameters into lists\n",
        "      first_layer_nodes.append(i) # append number of first layer nodes \n",
        "      second_layer_nodes.append(j) # append number of second layer nodes\n",
        "      first_layer_activation.append(firstActive) # append first layer activation function\n",
        "      second_layer_activation.append(secondActive) # append second layer activation function\n",
        "      output_layer_activation.append(outputActive) # append output layer activation function\n",
        "\n",
        "      modelName = f'NN_Model{str(counter)}' # generating model names to put into list\n",
        "      model_names.append(modelName) # appending name to model_names list\n",
        "\n",
        "      model = tf.keras.Model(inputs = inputLayer, outputs = outputLayer, name = modelName)\n",
        "\n",
        "      ### ----- Model Parameters ----- ###\n",
        "      if counter%2 == 0: \n",
        "        optFunction = tf.keras.optimizers.RMSprop(learning_rate =  0.025) # optimizer function\n",
        "        lossFunction = tf.keras.losses.Hinge() # loss function\n",
        "      else:\n",
        "        optFunction = tf.keras.optimizers.Adam(learning_rate =  0.025) # optimizer function\n",
        "        lossFunction = tf.keras.losses.SquaredHinge() # loss function  \n",
        "\n",
        "      optimizer_function.append(str(optFunction)) # append optimizer function\n",
        "      loss_function.append(str(lossFunction)) # append loss function\n",
        "\n",
        "      ### ----- Compiler ----- ###\n",
        "      model.compile(\n",
        "        optimizer = optFunction,\n",
        "        loss = lossFunction,\n",
        "        metrics = tf.keras.metrics.Accuracy()\n",
        "      )\n",
        "\n",
        "      ##### ----- Fitting the model ----- ###\n",
        "      print(f'first layer: {i}, second layer {j}') \n",
        "\n",
        "      tf.random.set_seed(42)\n",
        "\n",
        "      bSize = 200\n",
        "      epoch = 250\n",
        "      vSplit = 0.1\n",
        "      trainModel = model.fit(\n",
        "          x = xTrain,\n",
        "          y = yTrainCat,\n",
        "          batch_size = bSize,\n",
        "          epochs = epoch,\n",
        "          validation_split = vSplit\n",
        "      )\n",
        "\n",
        "      batch_size.append(bSize) # append batch size\n",
        "      num_of_epochs.append(epoch) # append number of epochs \n",
        "      \n",
        "      ### ----- Results ----- ###\n",
        "      # appending the validation accuracy into the list\n",
        "      training_loss.append(min(trainModel.history['loss'])) # append training loss\n",
        "      training_accuracy.append(max(trainModel.history['accuracy'])) # append training accuracy\n",
        "      validation_loss.append(min(trainModel.history['val_loss'])) # append validation loss\n",
        "      validation_accuracy.append(max(trainModel.history['val_accuracy'])) # append validation accuracy \n",
        "                                 \n",
        "      # appending the test accuracy into the list\n",
        "      finalResults = model.evaluate(xTest,yTestCat)\n",
        "\n",
        "      test_loss.append(finalResults[0]) # append test loss\n",
        "      test_accuracy.append(finalResults[1]) # append test accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87ukMxm5qPTy"
      },
      "source": [
        "### Running the hyper-parameter tunned Model ### \n",
        "This first round of models controls the number of nodes/perceptrons within the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84UX7eL7qOdx",
        "outputId": "d2950b37-228d-4729-ed8a-77909cedefd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first layer: 150, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 5ms/step - loss: 0.0884 - accuracy: 3.7037e-06 - val_loss: 0.0323 - val_accuracy: 1.5000e-04\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 2.4815e-04 - val_loss: 0.0237 - val_accuracy: 6.3333e-04\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 5.6481e-04 - val_loss: 0.0222 - val_accuracy: 7.6667e-04\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.0013 - val_loss: 0.0213 - val_accuracy: 0.0029\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.0034 - val_loss: 0.0229 - val_accuracy: 0.0029\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.0048 - val_loss: 0.0200 - val_accuracy: 0.0026\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.0058 - val_loss: 0.0208 - val_accuracy: 0.0060\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.0095 - val_loss: 0.0235 - val_accuracy: 0.0080\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.0121 - val_loss: 0.0227 - val_accuracy: 0.0108\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.0148 - val_loss: 0.0235 - val_accuracy: 0.0187\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.0187 - val_loss: 0.0234 - val_accuracy: 0.0208\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.0245 - val_loss: 0.0244 - val_accuracy: 0.0246\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.0264 - val_loss: 0.0285 - val_accuracy: 0.0250\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.0287 - val_loss: 0.0253 - val_accuracy: 0.0353\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.0358 - val_loss: 0.0267 - val_accuracy: 0.0474\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.0418 - val_loss: 0.0243 - val_accuracy: 0.0497\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.0484 - val_loss: 0.0235 - val_accuracy: 0.0514\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.0503 - val_loss: 0.0252 - val_accuracy: 0.0634\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.0579 - val_loss: 0.0305 - val_accuracy: 0.0649\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.0630 - val_loss: 0.0300 - val_accuracy: 0.0574\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.0757 - val_loss: 0.0327 - val_accuracy: 0.0944\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.0802 - val_loss: 0.0311 - val_accuracy: 0.1058\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.0897 - val_loss: 0.0289 - val_accuracy: 0.0802\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.0926 - val_loss: 0.0352 - val_accuracy: 0.1029\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.1047 - val_loss: 0.0353 - val_accuracy: 0.1130\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.1170 - val_loss: 0.0349 - val_accuracy: 0.1167\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.1105 - val_loss: 0.0337 - val_accuracy: 0.1218\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.1097 - val_loss: 0.0341 - val_accuracy: 0.1309\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.1252 - val_loss: 0.0323 - val_accuracy: 0.1267\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.1288 - val_loss: 0.0386 - val_accuracy: 0.1327\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.1368 - val_loss: 0.0349 - val_accuracy: 0.1602\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.1365 - val_loss: 0.0338 - val_accuracy: 0.1405\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.1533 - val_loss: 0.0343 - val_accuracy: 0.1616\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.1732 - val_loss: 0.0421 - val_accuracy: 0.1680\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.1587 - val_loss: 0.0395 - val_accuracy: 0.1832\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.1675 - val_loss: 0.0378 - val_accuracy: 0.1733\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.1845 - val_loss: 0.0359 - val_accuracy: 0.1884\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.1833 - val_loss: 0.0394 - val_accuracy: 0.2147\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.1913 - val_loss: 0.0380 - val_accuracy: 0.2151\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.2129 - val_loss: 0.0462 - val_accuracy: 0.2222\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.2156 - val_loss: 0.0469 - val_accuracy: 0.1954\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.2213 - val_loss: 0.0357 - val_accuracy: 0.2229\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.2192 - val_loss: 0.0425 - val_accuracy: 0.2399\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.2340 - val_loss: 0.0388 - val_accuracy: 0.2217\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.2222 - val_loss: 0.0415 - val_accuracy: 0.2568\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.2463 - val_loss: 0.0528 - val_accuracy: 0.2499\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.2457 - val_loss: 0.0580 - val_accuracy: 0.2673\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.2575 - val_loss: 0.0488 - val_accuracy: 0.2785\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.2647 - val_loss: 0.0613 - val_accuracy: 0.2940\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.2660 - val_loss: 0.0523 - val_accuracy: 0.2893\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.2644 - val_loss: 0.0562 - val_accuracy: 0.3110\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.2759 - val_loss: 0.0447 - val_accuracy: 0.2454\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.2746 - val_loss: 0.0545 - val_accuracy: 0.2531\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.2727 - val_loss: 0.0463 - val_accuracy: 0.2785\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.2703 - val_loss: 0.0471 - val_accuracy: 0.3011\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.2834 - val_loss: 0.0398 - val_accuracy: 0.2720\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.2860 - val_loss: 0.0596 - val_accuracy: 0.3208\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.3303 - val_loss: 0.0466 - val_accuracy: 0.3298\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.3441 - val_loss: 0.0526 - val_accuracy: 0.3484\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.3208 - val_loss: 0.0500 - val_accuracy: 0.3417\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.3016 - val_loss: 0.0447 - val_accuracy: 0.3023\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.2949 - val_loss: 0.0396 - val_accuracy: 0.3092\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.3070 - val_loss: 0.0503 - val_accuracy: 0.3430\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.3085 - val_loss: 0.0470 - val_accuracy: 0.3013\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.3157 - val_loss: 0.0552 - val_accuracy: 0.3377\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.3228 - val_loss: 0.0429 - val_accuracy: 0.3367\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.3264 - val_loss: 0.0487 - val_accuracy: 0.3097\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.3138 - val_loss: 0.0655 - val_accuracy: 0.3291\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.3287 - val_loss: 0.0589 - val_accuracy: 0.3543\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.3263 - val_loss: 0.0591 - val_accuracy: 0.3528\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.3292 - val_loss: 0.0543 - val_accuracy: 0.3254\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.3420 - val_loss: 0.0653 - val_accuracy: 0.3624\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.3525 - val_loss: 0.0543 - val_accuracy: 0.3694\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.3527 - val_loss: 0.0570 - val_accuracy: 0.3690\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.3521 - val_loss: 0.0589 - val_accuracy: 0.3744\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.3530 - val_loss: 0.0477 - val_accuracy: 0.3448\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.3665 - val_loss: 0.0608 - val_accuracy: 0.3922\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.3734 - val_loss: 0.0585 - val_accuracy: 0.4008\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.3967 - val_loss: 0.0453 - val_accuracy: 0.3839\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.4153 - val_loss: 0.0618 - val_accuracy: 0.4152\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.3886 - val_loss: 0.0552 - val_accuracy: 0.3781\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.3880 - val_loss: 0.0558 - val_accuracy: 0.4214\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.4234 - val_loss: 0.0667 - val_accuracy: 0.4938\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.4767 - val_loss: 0.0623 - val_accuracy: 0.4777\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.4713 - val_loss: 0.0699 - val_accuracy: 0.4677\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.4581 - val_loss: 0.0516 - val_accuracy: 0.4520\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.4595 - val_loss: 0.0600 - val_accuracy: 0.4769\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.4630 - val_loss: 0.0665 - val_accuracy: 0.4923\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.4893 - val_loss: 0.0670 - val_accuracy: 0.5106\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.5138 - val_loss: 0.0730 - val_accuracy: 0.5275\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.5072 - val_loss: 0.0655 - val_accuracy: 0.5562\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.5387 - val_loss: 0.0547 - val_accuracy: 0.5256\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.5289 - val_loss: 0.0675 - val_accuracy: 0.5299\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.5215 - val_loss: 0.0836 - val_accuracy: 0.5302\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.5339 - val_loss: 0.0627 - val_accuracy: 0.5680\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.5468 - val_loss: 0.0619 - val_accuracy: 0.5466\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.5157 - val_loss: 0.0617 - val_accuracy: 0.5074\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.5011 - val_loss: 0.0661 - val_accuracy: 0.5275\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.5372 - val_loss: 0.0670 - val_accuracy: 0.5325\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.5220 - val_loss: 0.0673 - val_accuracy: 0.5429\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.5412 - val_loss: 0.0643 - val_accuracy: 0.5243\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.5246 - val_loss: 0.0665 - val_accuracy: 0.5268\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.5564 - val_loss: 0.0814 - val_accuracy: 0.5723\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.5514 - val_loss: 0.0719 - val_accuracy: 0.5830\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.5945 - val_loss: 0.0715 - val_accuracy: 0.5775\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.5619 - val_loss: 0.0752 - val_accuracy: 0.6141\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.5984 - val_loss: 0.0881 - val_accuracy: 0.5889\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.5750 - val_loss: 0.0766 - val_accuracy: 0.6010\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.5789 - val_loss: 0.0892 - val_accuracy: 0.5682\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.5647 - val_loss: 0.0865 - val_accuracy: 0.6065\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.5905 - val_loss: 0.0809 - val_accuracy: 0.5858\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.5941 - val_loss: 0.0601 - val_accuracy: 0.5637\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.5809 - val_loss: 0.0988 - val_accuracy: 0.5897\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.5976 - val_loss: 0.0742 - val_accuracy: 0.5980\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.5839 - val_loss: 0.0921 - val_accuracy: 0.5954\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.6000 - val_loss: 0.0840 - val_accuracy: 0.6446\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.6017 - val_loss: 0.0877 - val_accuracy: 0.6107\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.5897 - val_loss: 0.0679 - val_accuracy: 0.6221\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.6104 - val_loss: 0.0772 - val_accuracy: 0.6378\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.5992 - val_loss: 0.0948 - val_accuracy: 0.6034\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.5869 - val_loss: 0.0959 - val_accuracy: 0.5954\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.5866 - val_loss: 0.0930 - val_accuracy: 0.6222\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.6131 - val_loss: 0.0970 - val_accuracy: 0.6173\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.6188 - val_loss: 0.0827 - val_accuracy: 0.6204\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.6289 - val_loss: 0.0868 - val_accuracy: 0.6428\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.6232 - val_loss: 0.0813 - val_accuracy: 0.6634\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.6357 - val_loss: 0.0943 - val_accuracy: 0.6455\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.6526 - val_loss: 0.0820 - val_accuracy: 0.6011\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.5975 - val_loss: 0.0807 - val_accuracy: 0.5841\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.5920 - val_loss: 0.0916 - val_accuracy: 0.6288\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.6442 - val_loss: 0.1025 - val_accuracy: 0.6714\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.6660 - val_loss: 0.1006 - val_accuracy: 0.6655\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.6414 - val_loss: 0.0993 - val_accuracy: 0.6366\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.6296 - val_loss: 0.0827 - val_accuracy: 0.6694\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.6488 - val_loss: 0.0811 - val_accuracy: 0.6621\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.6494 - val_loss: 0.0746 - val_accuracy: 0.6510\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.6525 - val_loss: 0.1027 - val_accuracy: 0.6273\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.6429 - val_loss: 0.0919 - val_accuracy: 0.6732\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.6680 - val_loss: 0.0865 - val_accuracy: 0.6699\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.6752 - val_loss: 0.0798 - val_accuracy: 0.6610\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.7008 - val_loss: 0.1111 - val_accuracy: 0.7276\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.7093 - val_loss: 0.0998 - val_accuracy: 0.7248\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.7235 - val_loss: 0.0851 - val_accuracy: 0.7329\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.7099 - val_loss: 0.1216 - val_accuracy: 0.6870\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.7022 - val_loss: 0.1115 - val_accuracy: 0.7166\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.7526 - val_loss: 0.1216 - val_accuracy: 0.7262\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.7237 - val_loss: 0.1191 - val_accuracy: 0.7157\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.7187 - val_loss: 0.0963 - val_accuracy: 0.7294\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.7434 - val_loss: 0.1139 - val_accuracy: 0.7424\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.7186 - val_loss: 0.1299 - val_accuracy: 0.7122\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.7058 - val_loss: 0.1052 - val_accuracy: 0.7193\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.6970 - val_loss: 0.1208 - val_accuracy: 0.6970\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.6960 - val_loss: 0.0906 - val_accuracy: 0.6974\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.7220 - val_loss: 0.1044 - val_accuracy: 0.7066\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.7264 - val_loss: 0.0928 - val_accuracy: 0.7422\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.7342 - val_loss: 0.0982 - val_accuracy: 0.7375\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.7373 - val_loss: 0.1212 - val_accuracy: 0.7502\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.7260 - val_loss: 0.1172 - val_accuracy: 0.7330\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.1338 - val_accuracy: 0.7311\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.7506 - val_loss: 0.1247 - val_accuracy: 0.7562\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.7533 - val_loss: 0.1104 - val_accuracy: 0.7292\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.7421 - val_loss: 0.1284 - val_accuracy: 0.7210\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.7469 - val_loss: 0.0976 - val_accuracy: 0.7567\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.7601 - val_loss: 0.1081 - val_accuracy: 0.7779\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.7675 - val_loss: 0.0916 - val_accuracy: 0.7476\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.7648 - val_loss: 0.1338 - val_accuracy: 0.7648\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.7646 - val_loss: 0.1167 - val_accuracy: 0.7654\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.7976 - val_loss: 0.1337 - val_accuracy: 0.8131\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.7705 - val_loss: 0.0843 - val_accuracy: 0.7435\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.7799 - val_loss: 0.1286 - val_accuracy: 0.7854\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.7607 - val_loss: 0.1158 - val_accuracy: 0.7513\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.7711 - val_loss: 0.1453 - val_accuracy: 0.7615\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.7747 - val_loss: 0.1194 - val_accuracy: 0.7765\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.7591 - val_loss: 0.1473 - val_accuracy: 0.7493\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.7510 - val_loss: 0.1069 - val_accuracy: 0.7402\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.7776 - val_loss: 0.1185 - val_accuracy: 0.7897\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.7986 - val_loss: 0.1350 - val_accuracy: 0.8019\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.7844 - val_loss: 0.0867 - val_accuracy: 0.7832\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.7770 - val_loss: 0.1041 - val_accuracy: 0.7707\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.7623 - val_loss: 0.1022 - val_accuracy: 0.7664\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.8033 - val_loss: 0.1220 - val_accuracy: 0.7821\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.7942 - val_loss: 0.1248 - val_accuracy: 0.7870\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.8073 - val_loss: 0.2745 - val_accuracy: 0.7936\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.8293 - val_loss: 0.1321 - val_accuracy: 0.8433\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.8003 - val_loss: 0.1158 - val_accuracy: 0.7827\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.7921 - val_loss: 0.1437 - val_accuracy: 0.7546\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.7663 - val_loss: 0.1833 - val_accuracy: 0.7755\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.8082 - val_loss: 0.1246 - val_accuracy: 0.7998\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8145 - val_loss: 0.1118 - val_accuracy: 0.8175\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.8328 - val_loss: 0.1262 - val_accuracy: 0.8402\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.8428 - val_loss: 0.1404 - val_accuracy: 0.8420\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.8440 - val_loss: 0.1229 - val_accuracy: 0.8189\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.8368 - val_loss: 0.1435 - val_accuracy: 0.8343\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.8247 - val_loss: 0.1300 - val_accuracy: 0.8308\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.8250 - val_loss: 0.1021 - val_accuracy: 0.8336\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.8394 - val_loss: 0.1435 - val_accuracy: 0.8337\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.8246 - val_loss: 0.1262 - val_accuracy: 0.8205\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.8320 - val_loss: 0.1323 - val_accuracy: 0.8191\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.8284 - val_loss: 0.1488 - val_accuracy: 0.8168\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.8178 - val_loss: 0.1180 - val_accuracy: 0.7950\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.7920\n",
            "first layer: 150, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 2.4074e-05 - val_loss: 0.0279 - val_accuracy: 3.3333e-05\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0288 - accuracy: 4.0000e-04 - val_loss: 0.0221 - val_accuracy: 0.0010\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.0011 - val_loss: 0.0198 - val_accuracy: 0.0013\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.0021 - val_loss: 0.0205 - val_accuracy: 0.0026\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0167 - accuracy: 0.0042 - val_loss: 0.0228 - val_accuracy: 0.0070\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.0065 - val_loss: 0.0220 - val_accuracy: 0.0052\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.0110 - val_loss: 0.0206 - val_accuracy: 0.0104\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.0133 - val_loss: 0.0208 - val_accuracy: 0.0132\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.0176 - val_loss: 0.0205 - val_accuracy: 0.0173\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.0214 - val_loss: 0.0203 - val_accuracy: 0.0174\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.0265 - val_loss: 0.0216 - val_accuracy: 0.0303\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.0282 - val_loss: 0.0223 - val_accuracy: 0.0378\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.0316 - val_loss: 0.0231 - val_accuracy: 0.0353\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.0334 - val_loss: 0.0233 - val_accuracy: 0.0416\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.0404 - val_loss: 0.0227 - val_accuracy: 0.0466\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.0466 - val_loss: 0.0223 - val_accuracy: 0.0534\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.0528 - val_loss: 0.0275 - val_accuracy: 0.0534\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.0515 - val_loss: 0.0280 - val_accuracy: 0.0532\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.0601 - val_loss: 0.0244 - val_accuracy: 0.0653\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.0636 - val_loss: 0.0254 - val_accuracy: 0.0684\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.0669 - val_loss: 0.0254 - val_accuracy: 0.0796\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.0718 - val_loss: 0.0287 - val_accuracy: 0.0731\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.0743 - val_loss: 0.0267 - val_accuracy: 0.0812\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.0839 - val_loss: 0.0326 - val_accuracy: 0.0837\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.0889 - val_loss: 0.0368 - val_accuracy: 0.0999\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.0870 - val_loss: 0.0272 - val_accuracy: 0.0866\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.0931 - val_loss: 0.0318 - val_accuracy: 0.1139\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.1019 - val_loss: 0.0314 - val_accuracy: 0.1228\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.1081 - val_loss: 0.0308 - val_accuracy: 0.1007\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.1192 - val_loss: 0.0354 - val_accuracy: 0.1147\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.1238 - val_loss: 0.0343 - val_accuracy: 0.1411\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.1428 - val_loss: 0.0337 - val_accuracy: 0.1501\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.1468 - val_loss: 0.0384 - val_accuracy: 0.1619\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.1426 - val_loss: 0.0313 - val_accuracy: 0.1440\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.1459 - val_loss: 0.0366 - val_accuracy: 0.1669\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.1516 - val_loss: 0.0379 - val_accuracy: 0.1738\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.1747 - val_loss: 0.0374 - val_accuracy: 0.2159\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.1982 - val_loss: 0.0351 - val_accuracy: 0.2006\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.1911 - val_loss: 0.0380 - val_accuracy: 0.2275\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.2210 - val_loss: 0.0410 - val_accuracy: 0.2499\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.2189 - val_loss: 0.0375 - val_accuracy: 0.2181\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.2160 - val_loss: 0.0465 - val_accuracy: 0.2406\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.2278 - val_loss: 0.0374 - val_accuracy: 0.2320\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.2245 - val_loss: 0.0425 - val_accuracy: 0.2825\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.2592 - val_loss: 0.0450 - val_accuracy: 0.2585\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.2692 - val_loss: 0.0435 - val_accuracy: 0.2924\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.2765 - val_loss: 0.0347 - val_accuracy: 0.2888\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.2819 - val_loss: 0.0482 - val_accuracy: 0.2909\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.2709 - val_loss: 0.0398 - val_accuracy: 0.2865\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.3021 - val_loss: 0.0541 - val_accuracy: 0.3530\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.3191 - val_loss: 0.0402 - val_accuracy: 0.3590\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.3295 - val_loss: 0.0442 - val_accuracy: 0.3478\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.3494 - val_loss: 0.0467 - val_accuracy: 0.3473\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.3432 - val_loss: 0.0499 - val_accuracy: 0.3715\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.3229 - val_loss: 0.0438 - val_accuracy: 0.3420\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.3266 - val_loss: 0.0444 - val_accuracy: 0.3309\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.3557 - val_loss: 0.0587 - val_accuracy: 0.4204\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.3732 - val_loss: 0.0483 - val_accuracy: 0.3947\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.3851 - val_loss: 0.0492 - val_accuracy: 0.3742\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.3966 - val_loss: 0.0518 - val_accuracy: 0.4012\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.4225 - val_loss: 0.0512 - val_accuracy: 0.4415\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.4187 - val_loss: 0.0534 - val_accuracy: 0.4352\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.4313 - val_loss: 0.0579 - val_accuracy: 0.4786\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.4642 - val_loss: 0.0660 - val_accuracy: 0.4920\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.4507 - val_loss: 0.0550 - val_accuracy: 0.4360\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.4479 - val_loss: 0.0570 - val_accuracy: 0.4492\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.4834 - val_loss: 0.0618 - val_accuracy: 0.4914\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.4726 - val_loss: 0.0600 - val_accuracy: 0.4699\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.4591 - val_loss: 0.0689 - val_accuracy: 0.4353\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.4777 - val_loss: 0.0719 - val_accuracy: 0.4926\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.4746 - val_loss: 0.0742 - val_accuracy: 0.4801\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.4600 - val_loss: 0.0664 - val_accuracy: 0.4740\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.4971 - val_loss: 0.0568 - val_accuracy: 0.5080\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.5138 - val_loss: 0.0571 - val_accuracy: 0.5064\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.4748 - val_loss: 0.0611 - val_accuracy: 0.4726\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.4732 - val_loss: 0.0671 - val_accuracy: 0.5228\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.5398 - val_loss: 0.0695 - val_accuracy: 0.5202\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.5212 - val_loss: 0.0790 - val_accuracy: 0.5637\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.5543 - val_loss: 0.0741 - val_accuracy: 0.5852\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.5732 - val_loss: 0.0853 - val_accuracy: 0.5665\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.5646 - val_loss: 0.0703 - val_accuracy: 0.5797\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.5836 - val_loss: 0.0769 - val_accuracy: 0.5971\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.5728 - val_loss: 0.0768 - val_accuracy: 0.5892\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.5823 - val_loss: 0.0732 - val_accuracy: 0.5735\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.6020 - val_loss: 0.0784 - val_accuracy: 0.6301\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.6350 - val_loss: 0.0742 - val_accuracy: 0.6654\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.6249 - val_loss: 0.0738 - val_accuracy: 0.6390\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.6466 - val_loss: 0.0850 - val_accuracy: 0.6525\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.6444 - val_loss: 0.0952 - val_accuracy: 0.6727\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.6488 - val_loss: 0.0938 - val_accuracy: 0.6687\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.6830 - val_loss: 0.0897 - val_accuracy: 0.6714\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.6545 - val_loss: 0.0935 - val_accuracy: 0.6419\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.6119 - val_loss: 0.0905 - val_accuracy: 0.6311\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.6264 - val_loss: 0.0748 - val_accuracy: 0.6410\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.6634 - val_loss: 0.0944 - val_accuracy: 0.6444\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.6481 - val_loss: 0.0933 - val_accuracy: 0.6563\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.6457 - val_loss: 0.0957 - val_accuracy: 0.6671\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.6651 - val_loss: 0.0749 - val_accuracy: 0.6729\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.6543 - val_loss: 0.0997 - val_accuracy: 0.6790\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.6681 - val_loss: 0.0862 - val_accuracy: 0.6967\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.6856 - val_loss: 0.0910 - val_accuracy: 0.6938\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.6630 - val_loss: 0.1165 - val_accuracy: 0.6847\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.6825 - val_loss: 0.1151 - val_accuracy: 0.7039\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.7207 - val_loss: 0.1120 - val_accuracy: 0.6904\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.7058 - val_loss: 0.0999 - val_accuracy: 0.7209\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.7044 - val_loss: 0.1142 - val_accuracy: 0.7087\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.7229 - val_loss: 0.1050 - val_accuracy: 0.7447\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.7050 - val_loss: 0.1212 - val_accuracy: 0.7132\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.6809 - val_loss: 0.0844 - val_accuracy: 0.6821\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.6958 - val_loss: 0.0901 - val_accuracy: 0.6890\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.6790 - val_loss: 0.0993 - val_accuracy: 0.7049\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.6875 - val_loss: 0.0959 - val_accuracy: 0.7082\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.7075 - val_loss: 0.1115 - val_accuracy: 0.6967\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.7041 - val_loss: 0.1321 - val_accuracy: 0.7111\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.7188 - val_loss: 0.1195 - val_accuracy: 0.7493\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.7471 - val_loss: 0.1107 - val_accuracy: 0.7387\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.7278 - val_loss: 0.1123 - val_accuracy: 0.7505\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.7447 - val_loss: 0.1070 - val_accuracy: 0.7577\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.7445 - val_loss: 0.0930 - val_accuracy: 0.7385\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.7312 - val_loss: 0.1012 - val_accuracy: 0.7146\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.7340 - val_loss: 0.1303 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.7717 - val_loss: 0.1408 - val_accuracy: 0.8018\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.7765 - val_loss: 0.1409 - val_accuracy: 0.7433\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.7692 - val_loss: 0.1533 - val_accuracy: 0.7558\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.7582 - val_loss: 0.1278 - val_accuracy: 0.7637\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.7650 - val_loss: 0.1272 - val_accuracy: 0.7997\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7788 - val_loss: 0.1367 - val_accuracy: 0.7897\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.7918 - val_loss: 0.1244 - val_accuracy: 0.7766\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.7866 - val_loss: 0.1462 - val_accuracy: 0.7988\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.7659 - val_loss: 0.1135 - val_accuracy: 0.7654\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.7828 - val_loss: 0.1325 - val_accuracy: 0.7753\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.7867 - val_loss: 0.1360 - val_accuracy: 0.7968\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.7885 - val_loss: 0.1365 - val_accuracy: 0.8045\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.7757 - val_loss: 0.1165 - val_accuracy: 0.7410\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.7683 - val_loss: 0.1035 - val_accuracy: 0.7355\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.7458 - val_loss: 0.1177 - val_accuracy: 0.7668\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.7886 - val_loss: 0.1228 - val_accuracy: 0.7528\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.7850 - val_loss: 0.1442 - val_accuracy: 0.7972\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.8028 - val_loss: 0.1132 - val_accuracy: 0.8192\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.8125 - val_loss: 0.1237 - val_accuracy: 0.7966\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.8046 - val_loss: 0.1027 - val_accuracy: 0.7674\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0133 - accuracy: 0.8052 - val_loss: 0.1473 - val_accuracy: 0.8104\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.8036 - val_loss: 0.1530 - val_accuracy: 0.7920\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.7814 - val_loss: 0.1441 - val_accuracy: 0.8177\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8181 - val_loss: 0.1418 - val_accuracy: 0.8212\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.8097 - val_loss: 0.1141 - val_accuracy: 0.8260\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.8288 - val_loss: 0.1189 - val_accuracy: 0.8207\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.8047 - val_loss: 0.1345 - val_accuracy: 0.8144\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.8313 - val_loss: 0.1408 - val_accuracy: 0.8150\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.8203 - val_loss: 0.1709 - val_accuracy: 0.8252\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.8245 - val_loss: 0.1636 - val_accuracy: 0.8407\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.8499 - val_loss: 0.1895 - val_accuracy: 0.8264\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.8207 - val_loss: 0.1354 - val_accuracy: 0.8273\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.8202 - val_loss: 0.1241 - val_accuracy: 0.8273\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8361 - val_loss: 0.1202 - val_accuracy: 0.8144\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.8174 - val_loss: 0.1364 - val_accuracy: 0.7959\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.8253 - val_loss: 0.1356 - val_accuracy: 0.8259\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.8540 - val_loss: 0.1537 - val_accuracy: 0.8521\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8371 - val_loss: 0.1564 - val_accuracy: 0.8347\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.8317 - val_loss: 0.1305 - val_accuracy: 0.8181\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.8368 - val_loss: 0.1446 - val_accuracy: 0.8438\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.8596 - val_loss: 0.1613 - val_accuracy: 0.8589\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.8556 - val_loss: 0.1818 - val_accuracy: 0.8628\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.8597 - val_loss: 0.1811 - val_accuracy: 0.8333\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.8288 - val_loss: 0.1751 - val_accuracy: 0.8228\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.8203 - val_loss: 0.1635 - val_accuracy: 0.8322\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.8302 - val_loss: 0.1436 - val_accuracy: 0.8444\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.8482 - val_loss: 0.1544 - val_accuracy: 0.8163\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.8298 - val_loss: 0.1646 - val_accuracy: 0.8444\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.8411 - val_loss: 0.1446 - val_accuracy: 0.8282\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.8303 - val_loss: 0.1027 - val_accuracy: 0.7990\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.8256 - val_loss: 0.1389 - val_accuracy: 0.8299\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.8434 - val_loss: 0.1386 - val_accuracy: 0.8239\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8468 - val_loss: 0.1698 - val_accuracy: 0.8684\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.8473 - val_loss: 0.1532 - val_accuracy: 0.8564\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.8323 - val_loss: 0.1287 - val_accuracy: 0.8365\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.8619 - val_loss: 0.1603 - val_accuracy: 0.8676\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.8573 - val_loss: 0.1631 - val_accuracy: 0.8540\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.8781 - val_loss: 0.1987 - val_accuracy: 0.8781\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.8866 - val_loss: 0.1807 - val_accuracy: 0.8621\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.8703 - val_loss: 0.2112 - val_accuracy: 0.8794\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.8814 - val_loss: 0.1727 - val_accuracy: 0.8436\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.8481 - val_loss: 0.1967 - val_accuracy: 0.8647\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.8772 - val_loss: 0.2146 - val_accuracy: 0.8694\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.8683 - val_loss: 0.1925 - val_accuracy: 0.8900\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.8794 - val_loss: 0.1742 - val_accuracy: 0.8774\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8748 - val_loss: 0.1645 - val_accuracy: 0.8605\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.8766 - val_loss: 0.1764 - val_accuracy: 0.8608\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.8778 - val_loss: 0.1533 - val_accuracy: 0.8708\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.8698 - val_loss: 0.2078 - val_accuracy: 0.8728\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.8584 - val_loss: 0.1968 - val_accuracy: 0.8102\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.8447 - val_loss: 0.1835 - val_accuracy: 0.8564\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.8746 - val_loss: 0.2164 - val_accuracy: 0.8904\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.8875 - val_loss: 0.2185 - val_accuracy: 0.9079\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.8984 - val_loss: 0.1858 - val_accuracy: 0.8832\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.8862 - val_loss: 0.2018 - val_accuracy: 0.9039\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.8911 - val_loss: 0.1755 - val_accuracy: 0.8701\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.8596 - val_loss: 0.1912 - val_accuracy: 0.8583\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.8779 - val_loss: 0.2095 - val_accuracy: 0.8554\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.8764 - val_loss: 0.2282 - val_accuracy: 0.8891\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2944 - accuracy: 0.8825\n",
            "first layer: 200, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0909 - accuracy: 5.5556e-05 - val_loss: 0.0283 - val_accuracy: 1.5000e-04\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 7.3519e-04 - val_loss: 0.0238 - val_accuracy: 3.5000e-04\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.0025 - val_loss: 0.0221 - val_accuracy: 0.0021\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.0032 - val_loss: 0.0208 - val_accuracy: 0.0025\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.0064 - val_loss: 0.0200 - val_accuracy: 0.0091\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.0094 - val_loss: 0.0191 - val_accuracy: 0.0062\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.0129 - val_loss: 0.0219 - val_accuracy: 0.0154\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 0.0162 - val_loss: 0.0227 - val_accuracy: 0.0139\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.0203 - val_loss: 0.0227 - val_accuracy: 0.0228\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.0252 - val_loss: 0.0211 - val_accuracy: 0.0245\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.0265 - val_loss: 0.0217 - val_accuracy: 0.0367\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.0352 - val_loss: 0.0230 - val_accuracy: 0.0331\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.0383 - val_loss: 0.0240 - val_accuracy: 0.0311\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.0433 - val_loss: 0.0265 - val_accuracy: 0.0465\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.0485 - val_loss: 0.0272 - val_accuracy: 0.0481\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.0556 - val_loss: 0.0250 - val_accuracy: 0.0555\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.0603 - val_loss: 0.0318 - val_accuracy: 0.0597\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.0649 - val_loss: 0.0272 - val_accuracy: 0.0784\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.0744 - val_loss: 0.0282 - val_accuracy: 0.0760\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.0754 - val_loss: 0.0308 - val_accuracy: 0.0724\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.0819 - val_loss: 0.0309 - val_accuracy: 0.0876\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.0816 - val_loss: 0.0310 - val_accuracy: 0.0903\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.0862 - val_loss: 0.0290 - val_accuracy: 0.0877\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.0940 - val_loss: 0.0286 - val_accuracy: 0.1002\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.0860 - val_loss: 0.0311 - val_accuracy: 0.1023\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.0992 - val_loss: 0.0295 - val_accuracy: 0.0935\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.1069 - val_loss: 0.0329 - val_accuracy: 0.1247\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.1123 - val_loss: 0.0310 - val_accuracy: 0.1258\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.1285 - val_loss: 0.0421 - val_accuracy: 0.1315\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.1280 - val_loss: 0.0335 - val_accuracy: 0.1317\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.1350 - val_loss: 0.0348 - val_accuracy: 0.1377\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.1343 - val_loss: 0.0352 - val_accuracy: 0.1347\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.1270 - val_loss: 0.0395 - val_accuracy: 0.1265\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.1328 - val_loss: 0.0323 - val_accuracy: 0.1454\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.1408 - val_loss: 0.0348 - val_accuracy: 0.1593\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.1558 - val_loss: 0.0379 - val_accuracy: 0.1651\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.1514 - val_loss: 0.0427 - val_accuracy: 0.1850\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.1716 - val_loss: 0.0389 - val_accuracy: 0.1731\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.1904 - val_loss: 0.0356 - val_accuracy: 0.1928\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.1890 - val_loss: 0.0402 - val_accuracy: 0.2129\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.2028 - val_loss: 0.0347 - val_accuracy: 0.2191\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.2154 - val_loss: 0.0463 - val_accuracy: 0.2083\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.2234 - val_loss: 0.0447 - val_accuracy: 0.2200\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.2317 - val_loss: 0.0482 - val_accuracy: 0.2568\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.2417 - val_loss: 0.0579 - val_accuracy: 0.2813\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.2623 - val_loss: 0.0432 - val_accuracy: 0.2845\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.2866 - val_loss: 0.0475 - val_accuracy: 0.3067\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.3112 - val_loss: 0.0460 - val_accuracy: 0.3117\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.2882 - val_loss: 0.0429 - val_accuracy: 0.3236\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.3098 - val_loss: 0.0545 - val_accuracy: 0.3297\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.3520 - val_loss: 0.0531 - val_accuracy: 0.3620\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.3491 - val_loss: 0.0575 - val_accuracy: 0.3714\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.3828 - val_loss: 0.0661 - val_accuracy: 0.3887\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.3572 - val_loss: 0.0516 - val_accuracy: 0.3565\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.3536 - val_loss: 0.0581 - val_accuracy: 0.3871\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.3799 - val_loss: 0.0566 - val_accuracy: 0.3732\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.3528 - val_loss: 0.0635 - val_accuracy: 0.3605\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.3601 - val_loss: 0.0578 - val_accuracy: 0.3751\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.3571 - val_loss: 0.0553 - val_accuracy: 0.3517\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.3536 - val_loss: 0.0472 - val_accuracy: 0.3639\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.4014 - val_loss: 0.0593 - val_accuracy: 0.4279\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.4122 - val_loss: 0.0737 - val_accuracy: 0.4219\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.4228 - val_loss: 0.0684 - val_accuracy: 0.4667\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.4121 - val_loss: 0.0567 - val_accuracy: 0.4144\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.4414 - val_loss: 0.0748 - val_accuracy: 0.4516\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.4438 - val_loss: 0.0698 - val_accuracy: 0.4547\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.4682 - val_loss: 0.0746 - val_accuracy: 0.4862\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.4779 - val_loss: 0.0739 - val_accuracy: 0.5076\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.4564 - val_loss: 0.0625 - val_accuracy: 0.4934\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.4907 - val_loss: 0.0687 - val_accuracy: 0.5308\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.5064 - val_loss: 0.0915 - val_accuracy: 0.5335\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.4743 - val_loss: 0.0732 - val_accuracy: 0.4992\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.5089 - val_loss: 0.0625 - val_accuracy: 0.5087\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.5160 - val_loss: 0.0660 - val_accuracy: 0.4973\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.4956 - val_loss: 0.0710 - val_accuracy: 0.5030\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.5192 - val_loss: 0.0734 - val_accuracy: 0.5229\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.5306 - val_loss: 0.0942 - val_accuracy: 0.5361\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.5371 - val_loss: 0.0780 - val_accuracy: 0.5767\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.5378 - val_loss: 0.0766 - val_accuracy: 0.5218\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.5134 - val_loss: 0.0734 - val_accuracy: 0.5351\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.5144 - val_loss: 0.0767 - val_accuracy: 0.5277\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.5706 - val_loss: 0.0906 - val_accuracy: 0.5970\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.5420 - val_loss: 0.0730 - val_accuracy: 0.5606\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.5526 - val_loss: 0.0881 - val_accuracy: 0.5784\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.5605 - val_loss: 0.0839 - val_accuracy: 0.5411\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.5771 - val_loss: 0.0825 - val_accuracy: 0.5985\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.5851 - val_loss: 0.0762 - val_accuracy: 0.5972\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.5676 - val_loss: 0.0764 - val_accuracy: 0.5753\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.5716 - val_loss: 0.0866 - val_accuracy: 0.5974\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.5776 - val_loss: 0.0975 - val_accuracy: 0.6097\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.6033 - val_loss: 0.0864 - val_accuracy: 0.6148\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.5987 - val_loss: 0.0761 - val_accuracy: 0.6114\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.6198 - val_loss: 0.1036 - val_accuracy: 0.6413\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.6435 - val_loss: 0.0632 - val_accuracy: 0.6320\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.6555 - val_loss: 0.0881 - val_accuracy: 0.6799\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.6906 - val_loss: 0.0798 - val_accuracy: 0.6825\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.6728 - val_loss: 0.0820 - val_accuracy: 0.6970\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.6562 - val_loss: 0.0739 - val_accuracy: 0.6575\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.6691 - val_loss: 0.0809 - val_accuracy: 0.6746\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.6733 - val_loss: 0.0758 - val_accuracy: 0.6787\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.6739 - val_loss: 0.0912 - val_accuracy: 0.6860\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.6709 - val_loss: 0.0954 - val_accuracy: 0.6617\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.6782 - val_loss: 0.0946 - val_accuracy: 0.7009\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.6976 - val_loss: 0.1090 - val_accuracy: 0.7237\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.6878 - val_loss: 0.0970 - val_accuracy: 0.7014\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.7023 - val_loss: 0.0925 - val_accuracy: 0.7290\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.7115 - val_loss: 0.1063 - val_accuracy: 0.7052\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.7074 - val_loss: 0.0841 - val_accuracy: 0.6795\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.6865 - val_loss: 0.0893 - val_accuracy: 0.6911\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.7134 - val_loss: 0.1035 - val_accuracy: 0.6959\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.6854 - val_loss: 0.1003 - val_accuracy: 0.7058\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.7111 - val_loss: 0.1064 - val_accuracy: 0.7467\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.7476 - val_loss: 0.1025 - val_accuracy: 0.7435\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.7214 - val_loss: 0.1051 - val_accuracy: 0.7180\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.7313 - val_loss: 0.0966 - val_accuracy: 0.7537\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.7659 - val_loss: 0.1126 - val_accuracy: 0.7791\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.7567 - val_loss: 0.1051 - val_accuracy: 0.7171\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.7349 - val_loss: 0.1064 - val_accuracy: 0.7308\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.7421 - val_loss: 0.1237 - val_accuracy: 0.7522\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.7407 - val_loss: 0.1011 - val_accuracy: 0.7382\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.7529 - val_loss: 0.0989 - val_accuracy: 0.7723\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.7522 - val_loss: 0.1207 - val_accuracy: 0.7730\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.7537 - val_loss: 0.1140 - val_accuracy: 0.7756\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.7800 - val_loss: 0.1189 - val_accuracy: 0.7877\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.7731 - val_loss: 0.1085 - val_accuracy: 0.7800\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7510 - val_loss: 0.1275 - val_accuracy: 0.7505\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.7584 - val_loss: 0.1247 - val_accuracy: 0.7737\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.7227 - val_loss: 0.1084 - val_accuracy: 0.7326\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.7468 - val_loss: 0.1117 - val_accuracy: 0.7525\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.7699 - val_loss: 0.1248 - val_accuracy: 0.8049\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.7863 - val_loss: 0.1377 - val_accuracy: 0.7763\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.7678 - val_loss: 0.1085 - val_accuracy: 0.7260\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.7540 - val_loss: 0.1045 - val_accuracy: 0.7283\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.7413 - val_loss: 0.1105 - val_accuracy: 0.7576\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.7578 - val_loss: 0.1216 - val_accuracy: 0.7640\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.7736 - val_loss: 0.1158 - val_accuracy: 0.7681\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.7701 - val_loss: 0.1636 - val_accuracy: 0.7562\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.7234 - val_loss: 0.1327 - val_accuracy: 0.7209\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.7433 - val_loss: 0.1284 - val_accuracy: 0.7455\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.7356 - val_loss: 0.1728 - val_accuracy: 0.7345\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.7394 - val_loss: 0.1380 - val_accuracy: 0.7786\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.7396 - val_loss: 0.0952 - val_accuracy: 0.7402\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.7677 - val_loss: 0.1116 - val_accuracy: 0.7483\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.7876 - val_loss: 0.1444 - val_accuracy: 0.8104\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.8105 - val_loss: 0.1304 - val_accuracy: 0.7811\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.7875 - val_loss: 0.1171 - val_accuracy: 0.7960\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.8076 - val_loss: 0.1324 - val_accuracy: 0.8151\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.8170 - val_loss: 0.1639 - val_accuracy: 0.8193\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.8161 - val_loss: 0.1790 - val_accuracy: 0.8199\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.8171 - val_loss: 0.1321 - val_accuracy: 0.7935\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.8348 - val_loss: 0.1713 - val_accuracy: 0.8375\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.8323 - val_loss: 0.1304 - val_accuracy: 0.8179\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.8279 - val_loss: 0.1645 - val_accuracy: 0.8101\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.7887 - val_loss: 0.1363 - val_accuracy: 0.7724\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.8142 - val_loss: 0.1529 - val_accuracy: 0.8443\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.8452 - val_loss: 0.1601 - val_accuracy: 0.8508\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.8439 - val_loss: 0.1522 - val_accuracy: 0.8490\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.8529 - val_loss: 0.1620 - val_accuracy: 0.8585\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.8556 - val_loss: 0.1758 - val_accuracy: 0.8409\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.8473 - val_loss: 0.1646 - val_accuracy: 0.8391\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.8459 - val_loss: 0.1738 - val_accuracy: 0.8453\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8626 - val_loss: 0.1899 - val_accuracy: 0.8779\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.8676 - val_loss: 0.1682 - val_accuracy: 0.8771\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.8803 - val_loss: 0.1664 - val_accuracy: 0.8756\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.8542 - val_loss: 0.1614 - val_accuracy: 0.8715\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.8365 - val_loss: 0.1658 - val_accuracy: 0.8401\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.8442 - val_loss: 0.1770 - val_accuracy: 0.8450\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.8529 - val_loss: 0.1551 - val_accuracy: 0.8432\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.8431 - val_loss: 0.1776 - val_accuracy: 0.8503\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.8736 - val_loss: 0.2224 - val_accuracy: 0.8946\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.8596 - val_loss: 0.1660 - val_accuracy: 0.8617\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.8577 - val_loss: 0.1539 - val_accuracy: 0.8471\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.8523 - val_loss: 0.1455 - val_accuracy: 0.8667\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0136 - accuracy: 0.8531 - val_loss: 0.1229 - val_accuracy: 0.8472\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.8487 - val_loss: 0.1527 - val_accuracy: 0.8407\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.8578 - val_loss: 0.1581 - val_accuracy: 0.8549\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.8574 - val_loss: 0.1623 - val_accuracy: 0.8617\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.8706 - val_loss: 0.2008 - val_accuracy: 0.8767\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.8670 - val_loss: 0.1763 - val_accuracy: 0.8646\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.8596 - val_loss: 0.1712 - val_accuracy: 0.8500\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.8682 - val_loss: 0.1693 - val_accuracy: 0.8902\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.8802 - val_loss: 0.1660 - val_accuracy: 0.8562\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.8729 - val_loss: 0.1340 - val_accuracy: 0.8504\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.8565 - val_loss: 0.1817 - val_accuracy: 0.8607\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.8771 - val_loss: 0.1891 - val_accuracy: 0.8633\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.8628 - val_loss: 0.1349 - val_accuracy: 0.8537\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.8667 - val_loss: 0.1674 - val_accuracy: 0.8565\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.8565 - val_loss: 0.1827 - val_accuracy: 0.8459\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.8772 - val_loss: 0.2021 - val_accuracy: 0.8810\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.8718 - val_loss: 0.1986 - val_accuracy: 0.8340\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.8565 - val_loss: 0.1807 - val_accuracy: 0.8389\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.8414 - val_loss: 0.1634 - val_accuracy: 0.8375\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.8336 - val_loss: 0.1541 - val_accuracy: 0.8349\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.8524 - val_loss: 0.1699 - val_accuracy: 0.8707\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.8960 - val_loss: 0.1882 - val_accuracy: 0.8846\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.8699 - val_loss: 0.1354 - val_accuracy: 0.8531\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.8524 - val_loss: 0.1944 - val_accuracy: 0.8804\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.8737 - val_loss: 0.2320 - val_accuracy: 0.8849\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.8739 - val_loss: 0.1406 - val_accuracy: 0.8719\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.8637 - val_loss: 0.1577 - val_accuracy: 0.8529\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.8415\n",
            "first layer: 200, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 2.7778e-05 - val_loss: 0.0312 - val_accuracy: 4.8333e-04\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 4.4074e-04 - val_loss: 0.0256 - val_accuracy: 3.6667e-04\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.0011 - val_loss: 0.0227 - val_accuracy: 0.0026\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.0024 - val_loss: 0.0198 - val_accuracy: 0.0019\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0175 - accuracy: 0.0046 - val_loss: 0.0203 - val_accuracy: 0.0061\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.0069 - val_loss: 0.0197 - val_accuracy: 0.0037\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.0087 - val_loss: 0.0205 - val_accuracy: 0.0086\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.0109 - val_loss: 0.0236 - val_accuracy: 0.0130\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 0.0146 - val_loss: 0.0226 - val_accuracy: 0.0169\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.0193 - val_loss: 0.0210 - val_accuracy: 0.0239\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.0209 - val_loss: 0.0242 - val_accuracy: 0.0280\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.0253 - val_loss: 0.0227 - val_accuracy: 0.0242\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.0289 - val_loss: 0.0227 - val_accuracy: 0.0302\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.0311 - val_loss: 0.0216 - val_accuracy: 0.0338\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.0347 - val_loss: 0.0211 - val_accuracy: 0.0363\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.0397 - val_loss: 0.0241 - val_accuracy: 0.0412\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.0410 - val_loss: 0.0270 - val_accuracy: 0.0461\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.0471 - val_loss: 0.0289 - val_accuracy: 0.0473\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.0495 - val_loss: 0.0260 - val_accuracy: 0.0662\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.0575 - val_loss: 0.0274 - val_accuracy: 0.0598\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.0587 - val_loss: 0.0273 - val_accuracy: 0.0650\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.0665 - val_loss: 0.0253 - val_accuracy: 0.0659\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.0689 - val_loss: 0.0277 - val_accuracy: 0.0766\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.0739 - val_loss: 0.0339 - val_accuracy: 0.0817\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.0741 - val_loss: 0.0261 - val_accuracy: 0.0860\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.0798 - val_loss: 0.0314 - val_accuracy: 0.0826\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.0825 - val_loss: 0.0314 - val_accuracy: 0.0861\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.0911 - val_loss: 0.0341 - val_accuracy: 0.0949\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.0970 - val_loss: 0.0375 - val_accuracy: 0.0954\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.0967 - val_loss: 0.0294 - val_accuracy: 0.1057\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.1085 - val_loss: 0.0318 - val_accuracy: 0.1111\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.1138 - val_loss: 0.0298 - val_accuracy: 0.1116\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.1209 - val_loss: 0.0370 - val_accuracy: 0.1345\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.1217 - val_loss: 0.0323 - val_accuracy: 0.1347\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.1310 - val_loss: 0.0324 - val_accuracy: 0.1279\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.1364 - val_loss: 0.0355 - val_accuracy: 0.1351\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.1534 - val_loss: 0.0368 - val_accuracy: 0.1833\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.1864 - val_loss: 0.0455 - val_accuracy: 0.2161\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.1874 - val_loss: 0.0385 - val_accuracy: 0.1596\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.1693 - val_loss: 0.0384 - val_accuracy: 0.1744\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.1711 - val_loss: 0.0398 - val_accuracy: 0.1851\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.1750 - val_loss: 0.0382 - val_accuracy: 0.1825\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.1767 - val_loss: 0.0364 - val_accuracy: 0.1830\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.1823 - val_loss: 0.0421 - val_accuracy: 0.2181\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.1952 - val_loss: 0.0359 - val_accuracy: 0.2139\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.2162 - val_loss: 0.0431 - val_accuracy: 0.2146\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.2176 - val_loss: 0.0398 - val_accuracy: 0.2245\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.2370 - val_loss: 0.0468 - val_accuracy: 0.2482\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.2344 - val_loss: 0.0448 - val_accuracy: 0.2396\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.2458 - val_loss: 0.0389 - val_accuracy: 0.2840\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.2518 - val_loss: 0.0475 - val_accuracy: 0.2846\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.2574 - val_loss: 0.0471 - val_accuracy: 0.2291\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.2492 - val_loss: 0.0420 - val_accuracy: 0.2683\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.2674 - val_loss: 0.0540 - val_accuracy: 0.2767\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.2984 - val_loss: 0.0438 - val_accuracy: 0.3140\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.3060 - val_loss: 0.0572 - val_accuracy: 0.3071\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.3110 - val_loss: 0.0571 - val_accuracy: 0.3290\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.3119 - val_loss: 0.0521 - val_accuracy: 0.3668\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.3378 - val_loss: 0.0535 - val_accuracy: 0.3274\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.3228 - val_loss: 0.0510 - val_accuracy: 0.2905\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.3063 - val_loss: 0.0426 - val_accuracy: 0.3248\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.3145 - val_loss: 0.0496 - val_accuracy: 0.3047\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.3320 - val_loss: 0.0495 - val_accuracy: 0.3597\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.3309 - val_loss: 0.0540 - val_accuracy: 0.3297\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.3130 - val_loss: 0.0532 - val_accuracy: 0.3306\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.3550 - val_loss: 0.0520 - val_accuracy: 0.3426\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.3327 - val_loss: 0.0566 - val_accuracy: 0.3682\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.3592 - val_loss: 0.0690 - val_accuracy: 0.3742\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.3723 - val_loss: 0.0581 - val_accuracy: 0.3899\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.3842 - val_loss: 0.0559 - val_accuracy: 0.3861\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.3797 - val_loss: 0.0561 - val_accuracy: 0.3841\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.3651 - val_loss: 0.0460 - val_accuracy: 0.3883\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.3746 - val_loss: 0.0619 - val_accuracy: 0.3601\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.3950 - val_loss: 0.0588 - val_accuracy: 0.4033\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.4173 - val_loss: 0.0652 - val_accuracy: 0.4195\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.4686 - val_loss: 0.0765 - val_accuracy: 0.5086\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.4538 - val_loss: 0.0656 - val_accuracy: 0.4784\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.4345 - val_loss: 0.0579 - val_accuracy: 0.4456\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.4542 - val_loss: 0.0705 - val_accuracy: 0.4957\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.4733 - val_loss: 0.0600 - val_accuracy: 0.4832\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.4680 - val_loss: 0.0671 - val_accuracy: 0.4895\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.4754 - val_loss: 0.0623 - val_accuracy: 0.4769\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.4562 - val_loss: 0.0636 - val_accuracy: 0.4397\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.4485 - val_loss: 0.0516 - val_accuracy: 0.4526\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.4582 - val_loss: 0.0620 - val_accuracy: 0.4761\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.4665 - val_loss: 0.0672 - val_accuracy: 0.4523\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.4849 - val_loss: 0.0650 - val_accuracy: 0.5234\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.5244 - val_loss: 0.0608 - val_accuracy: 0.4893\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.4708 - val_loss: 0.0819 - val_accuracy: 0.5340\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.5166 - val_loss: 0.0801 - val_accuracy: 0.5277\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.5292 - val_loss: 0.0823 - val_accuracy: 0.5439\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.5255 - val_loss: 0.0787 - val_accuracy: 0.5169\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.5129 - val_loss: 0.0761 - val_accuracy: 0.5411\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.5320 - val_loss: 0.0991 - val_accuracy: 0.5438\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.5490 - val_loss: 0.0755 - val_accuracy: 0.5968\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.5503 - val_loss: 0.0906 - val_accuracy: 0.5236\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.5224 - val_loss: 0.0748 - val_accuracy: 0.5253\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.5413 - val_loss: 0.0719 - val_accuracy: 0.5436\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.5158 - val_loss: 0.0767 - val_accuracy: 0.4906\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.5126 - val_loss: 0.0875 - val_accuracy: 0.5589\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.5247 - val_loss: 0.0788 - val_accuracy: 0.5620\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.5410 - val_loss: 0.0644 - val_accuracy: 0.5516\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.5466 - val_loss: 0.0835 - val_accuracy: 0.5395\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.5471 - val_loss: 0.0855 - val_accuracy: 0.5729\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.5906 - val_loss: 0.1082 - val_accuracy: 0.6287\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.6170 - val_loss: 0.0782 - val_accuracy: 0.6426\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.6450 - val_loss: 0.0953 - val_accuracy: 0.6622\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.6053 - val_loss: 0.0962 - val_accuracy: 0.6202\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.6038 - val_loss: 0.0808 - val_accuracy: 0.6201\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.6070 - val_loss: 0.0802 - val_accuracy: 0.6336\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.6300 - val_loss: 0.0886 - val_accuracy: 0.6504\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.6059 - val_loss: 0.1191 - val_accuracy: 0.6084\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.6189 - val_loss: 0.0943 - val_accuracy: 0.5953\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.6070 - val_loss: 0.0839 - val_accuracy: 0.6026\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.6129 - val_loss: 0.0849 - val_accuracy: 0.6106\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.6157 - val_loss: 0.1008 - val_accuracy: 0.6431\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.5880 - val_loss: 0.0864 - val_accuracy: 0.6174\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.5913 - val_loss: 0.0877 - val_accuracy: 0.5936\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.6139 - val_loss: 0.0790 - val_accuracy: 0.5830\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.6135 - val_loss: 0.0836 - val_accuracy: 0.6465\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.6187 - val_loss: 0.0764 - val_accuracy: 0.6198\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.6394 - val_loss: 0.1000 - val_accuracy: 0.6361\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.6492 - val_loss: 0.0858 - val_accuracy: 0.6812\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.6386 - val_loss: 0.0942 - val_accuracy: 0.6314\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.6426 - val_loss: 0.0903 - val_accuracy: 0.6788\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.6622 - val_loss: 0.0998 - val_accuracy: 0.6402\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.6580 - val_loss: 0.1199 - val_accuracy: 0.6756\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.6893 - val_loss: 0.1129 - val_accuracy: 0.7163\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.6984 - val_loss: 0.1056 - val_accuracy: 0.7038\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.6984 - val_loss: 0.1052 - val_accuracy: 0.7092\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.6814 - val_loss: 0.0962 - val_accuracy: 0.6867\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.6774 - val_loss: 0.0869 - val_accuracy: 0.6699\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.6819 - val_loss: 0.0993 - val_accuracy: 0.7053\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7067 - val_loss: 0.0943 - val_accuracy: 0.7218\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.7160 - val_loss: 0.1066 - val_accuracy: 0.7171\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.7162 - val_loss: 0.1101 - val_accuracy: 0.7032\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.7071 - val_loss: 0.1118 - val_accuracy: 0.7452\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.7279 - val_loss: 0.1268 - val_accuracy: 0.7285\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.7487 - val_loss: 0.1155 - val_accuracy: 0.7790\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.7460 - val_loss: 0.1405 - val_accuracy: 0.7609\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.7199 - val_loss: 0.1028 - val_accuracy: 0.7016\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.7227 - val_loss: 0.0979 - val_accuracy: 0.7466\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.7279 - val_loss: 0.1094 - val_accuracy: 0.7635\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.7498 - val_loss: 0.1059 - val_accuracy: 0.7181\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.7342 - val_loss: 0.0923 - val_accuracy: 0.7006\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.7053 - val_loss: 0.1149 - val_accuracy: 0.7106\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.7016 - val_loss: 0.1035 - val_accuracy: 0.7086\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.7351 - val_loss: 0.1069 - val_accuracy: 0.7405\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.7409 - val_loss: 0.1331 - val_accuracy: 0.7250\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.7227 - val_loss: 0.1113 - val_accuracy: 0.7121\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.7253 - val_loss: 0.1175 - val_accuracy: 0.7246\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.7542 - val_loss: 0.1099 - val_accuracy: 0.7304\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.7589 - val_loss: 0.0858 - val_accuracy: 0.7275\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.7504 - val_loss: 0.1188 - val_accuracy: 0.7834\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.7565 - val_loss: 0.1184 - val_accuracy: 0.7677\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.7637 - val_loss: 0.1135 - val_accuracy: 0.7405\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.7599 - val_loss: 0.1424 - val_accuracy: 0.7432\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.7887 - val_loss: 0.1143 - val_accuracy: 0.7866\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.7972 - val_loss: 0.1154 - val_accuracy: 0.8098\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.7955 - val_loss: 0.1494 - val_accuracy: 0.7900\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.7854 - val_loss: 0.1115 - val_accuracy: 0.7762\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.7859 - val_loss: 0.1427 - val_accuracy: 0.7938\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.7826 - val_loss: 0.1345 - val_accuracy: 0.7843\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.7994 - val_loss: 0.1474 - val_accuracy: 0.7942\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.8049 - val_loss: 0.1264 - val_accuracy: 0.8213\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.8033 - val_loss: 0.1206 - val_accuracy: 0.8068\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.8162 - val_loss: 0.1333 - val_accuracy: 0.7974\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.8189 - val_loss: 0.1308 - val_accuracy: 0.8116\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.8039 - val_loss: 0.1452 - val_accuracy: 0.8036\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.8060 - val_loss: 0.1440 - val_accuracy: 0.8060\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.7886 - val_loss: 0.1243 - val_accuracy: 0.7833\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.7868 - val_loss: 0.1614 - val_accuracy: 0.7966\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.7948 - val_loss: 0.1655 - val_accuracy: 0.8071\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.8223 - val_loss: 0.1585 - val_accuracy: 0.8451\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.8420 - val_loss: 0.1375 - val_accuracy: 0.8170\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8152 - val_loss: 0.1662 - val_accuracy: 0.8353\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.8265 - val_loss: 0.1379 - val_accuracy: 0.8209\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.8180 - val_loss: 0.1597 - val_accuracy: 0.8349\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.8358 - val_loss: 0.1640 - val_accuracy: 0.8368\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8259 - val_loss: 0.1688 - val_accuracy: 0.8318\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.8062 - val_loss: 0.1302 - val_accuracy: 0.7782\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.8031 - val_loss: 0.1369 - val_accuracy: 0.8116\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.8051 - val_loss: 0.1768 - val_accuracy: 0.8167\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.8299 - val_loss: 0.2167 - val_accuracy: 0.8419\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.7886 - val_loss: 0.1516 - val_accuracy: 0.7793\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.8011 - val_loss: 0.1751 - val_accuracy: 0.8169\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.8086 - val_loss: 0.1913 - val_accuracy: 0.8293\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.8290 - val_loss: 0.1494 - val_accuracy: 0.7928\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.8077 - val_loss: 0.1490 - val_accuracy: 0.8253\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.8374 - val_loss: 0.1601 - val_accuracy: 0.8414\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.8127 - val_loss: 0.1578 - val_accuracy: 0.7998\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.8108 - val_loss: 0.1425 - val_accuracy: 0.8182\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.8324 - val_loss: 0.1581 - val_accuracy: 0.8327\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.8483 - val_loss: 0.1901 - val_accuracy: 0.8345\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.8302 - val_loss: 0.1479 - val_accuracy: 0.7984\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0142 - accuracy: 0.8149 - val_loss: 0.1484 - val_accuracy: 0.8252\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.8400 - val_loss: 0.2400 - val_accuracy: 0.8872\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.8648 - val_loss: 0.2266 - val_accuracy: 0.8632\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.8750 - val_loss: 0.2018 - val_accuracy: 0.8726\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.8557 - val_loss: 0.2087 - val_accuracy: 0.8206\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.8122\n"
          ]
        }
      ],
      "source": [
        "if device_name != '/device:GPU:0':  \n",
        "  model_builder1()\n",
        "else:\n",
        "    with tf.device('GPU:0'):\n",
        "        model_builder1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first layer: 150, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0800 - accuracy: 0.0000e+00 - val_loss: 1.0798 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0795 - accuracy: 0.0000e+00 - val_loss: 1.0792 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0790 - accuracy: 0.0000e+00 - val_loss: 1.0786 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.0000e+00 - val_loss: 1.0780 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0777 - accuracy: 0.0000e+00 - val_loss: 1.0771 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0768 - accuracy: 0.0000e+00 - val_loss: 1.0760 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0755 - accuracy: 0.0000e+00 - val_loss: 1.0744 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0734 - accuracy: 0.0000e+00 - val_loss: 1.0715 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0695 - accuracy: 0.0000e+00 - val_loss: 1.0666 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0646 - accuracy: 0.0000e+00 - val_loss: 1.0616 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0598 - accuracy: 0.0000e+00 - val_loss: 1.0564 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0541 - accuracy: 0.0000e+00 - val_loss: 1.0495 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0464 - accuracy: 0.0000e+00 - val_loss: 1.0400 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0361 - accuracy: 0.0000e+00 - val_loss: 1.0275 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0237 - accuracy: 0.0000e+00 - val_loss: 1.0139 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0119 - accuracy: 0.0000e+00 - val_loss: 1.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0027 - accuracy: 0.0000e+00 - val_loss: 0.9942 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9959 - accuracy: 0.0000e+00 - val_loss: 0.9881 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9908 - accuracy: 0.0000e+00 - val_loss: 0.9836 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9867 - accuracy: 0.0000e+00 - val_loss: 0.9795 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9819 - accuracy: 0.0000e+00 - val_loss: 0.9735 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9770 - accuracy: 0.0000e+00 - val_loss: 0.9696 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9737 - accuracy: 0.0000e+00 - val_loss: 0.9666 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9710 - accuracy: 0.0000e+00 - val_loss: 0.9642 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9688 - accuracy: 0.0000e+00 - val_loss: 0.9621 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9667 - accuracy: 0.0000e+00 - val_loss: 0.9599 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9639 - accuracy: 0.0000e+00 - val_loss: 0.9562 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9607 - accuracy: 0.0000e+00 - val_loss: 0.9534 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9582 - accuracy: 0.0000e+00 - val_loss: 0.9512 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9562 - accuracy: 0.0000e+00 - val_loss: 0.9494 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9544 - accuracy: 0.0000e+00 - val_loss: 0.9478 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9529 - accuracy: 0.0000e+00 - val_loss: 0.9465 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 0.0000e+00 - val_loss: 0.9453 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9504 - accuracy: 0.0000e+00 - val_loss: 0.9443 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9493 - accuracy: 0.0000e+00 - val_loss: 0.9434 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 1.8519e-06 - val_loss: 0.9427 - val_accuracy: 1.6667e-05\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9476 - accuracy: 1.8519e-06 - val_loss: 0.9419 - val_accuracy: 1.6667e-05\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9468 - accuracy: 1.8519e-06 - val_loss: 0.9413 - val_accuracy: 1.6667e-05\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9461 - accuracy: 1.8519e-06 - val_loss: 0.9407 - val_accuracy: 1.6667e-05\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9455 - accuracy: 5.5556e-06 - val_loss: 0.9402 - val_accuracy: 1.6667e-05\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9449 - accuracy: 7.4074e-06 - val_loss: 0.9397 - val_accuracy: 3.3333e-05\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9443 - accuracy: 7.4074e-06 - val_loss: 0.9393 - val_accuracy: 3.3333e-05\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9438 - accuracy: 7.4074e-06 - val_loss: 0.9388 - val_accuracy: 3.3333e-05\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9434 - accuracy: 1.4815e-05 - val_loss: 0.9385 - val_accuracy: 3.3333e-05\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9430 - accuracy: 1.8519e-05 - val_loss: 0.9381 - val_accuracy: 3.3333e-05\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9426 - accuracy: 3.1481e-05 - val_loss: 0.9378 - val_accuracy: 3.3333e-05\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9422 - accuracy: 4.0741e-05 - val_loss: 0.9375 - val_accuracy: 3.3333e-05\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9418 - accuracy: 4.4444e-05 - val_loss: 0.9372 - val_accuracy: 3.3333e-05\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9415 - accuracy: 5.1852e-05 - val_loss: 0.9369 - val_accuracy: 6.6667e-05\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9412 - accuracy: 7.0370e-05 - val_loss: 0.9367 - val_accuracy: 8.3333e-05\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9409 - accuracy: 8.1481e-05 - val_loss: 0.9364 - val_accuracy: 8.3333e-05\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9406 - accuracy: 9.4444e-05 - val_loss: 0.9362 - val_accuracy: 1.1667e-04\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9403 - accuracy: 1.0741e-04 - val_loss: 0.9360 - val_accuracy: 1.1667e-04\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9401 - accuracy: 1.2963e-04 - val_loss: 0.9358 - val_accuracy: 1.1667e-04\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9398 - accuracy: 1.4259e-04 - val_loss: 0.9356 - val_accuracy: 1.6667e-04\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9396 - accuracy: 1.7778e-04 - val_loss: 0.9354 - val_accuracy: 1.8333e-04\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9394 - accuracy: 1.8889e-04 - val_loss: 0.9352 - val_accuracy: 1.8333e-04\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9392 - accuracy: 2.0741e-04 - val_loss: 0.9351 - val_accuracy: 2.1667e-04\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9390 - accuracy: 2.2407e-04 - val_loss: 0.9349 - val_accuracy: 2.3333e-04\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9388 - accuracy: 2.5370e-04 - val_loss: 0.9347 - val_accuracy: 2.5000e-04\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9386 - accuracy: 2.6481e-04 - val_loss: 0.9346 - val_accuracy: 2.6667e-04\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9384 - accuracy: 2.9815e-04 - val_loss: 0.9345 - val_accuracy: 2.8333e-04\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9383 - accuracy: 3.0926e-04 - val_loss: 0.9343 - val_accuracy: 2.8333e-04\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9381 - accuracy: 3.3889e-04 - val_loss: 0.9342 - val_accuracy: 2.8333e-04\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9379 - accuracy: 3.6852e-04 - val_loss: 0.9341 - val_accuracy: 3.0000e-04\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9378 - accuracy: 4.0185e-04 - val_loss: 0.9339 - val_accuracy: 3.1667e-04\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9376 - accuracy: 4.2407e-04 - val_loss: 0.9338 - val_accuracy: 3.3333e-04\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9375 - accuracy: 4.5741e-04 - val_loss: 0.9337 - val_accuracy: 3.8333e-04\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9373 - accuracy: 4.9444e-04 - val_loss: 0.9336 - val_accuracy: 3.5000e-04\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9372 - accuracy: 5.0556e-04 - val_loss: 0.9335 - val_accuracy: 4.3333e-04\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9371 - accuracy: 5.5926e-04 - val_loss: 0.9334 - val_accuracy: 4.3333e-04\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9370 - accuracy: 5.9074e-04 - val_loss: 0.9333 - val_accuracy: 5.0000e-04\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9368 - accuracy: 6.3333e-04 - val_loss: 0.9332 - val_accuracy: 5.1667e-04\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9367 - accuracy: 6.6111e-04 - val_loss: 0.9331 - val_accuracy: 5.8333e-04\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9366 - accuracy: 7.0185e-04 - val_loss: 0.9330 - val_accuracy: 6.3333e-04\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9365 - accuracy: 7.5000e-04 - val_loss: 0.9329 - val_accuracy: 6.3333e-04\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9364 - accuracy: 8.0000e-04 - val_loss: 0.9328 - val_accuracy: 6.1667e-04\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9363 - accuracy: 8.2037e-04 - val_loss: 0.9328 - val_accuracy: 6.8333e-04\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9362 - accuracy: 8.8519e-04 - val_loss: 0.9327 - val_accuracy: 7.5000e-04\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9361 - accuracy: 9.1111e-04 - val_loss: 0.9326 - val_accuracy: 8.3333e-04\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9360 - accuracy: 9.7778e-04 - val_loss: 0.9325 - val_accuracy: 8.6667e-04\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9359 - accuracy: 0.0010 - val_loss: 0.9325 - val_accuracy: 9.1667e-04\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9358 - accuracy: 0.0010 - val_loss: 0.9324 - val_accuracy: 9.8333e-04\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9357 - accuracy: 0.0011 - val_loss: 0.9323 - val_accuracy: 0.0010\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9356 - accuracy: 0.0011 - val_loss: 0.9323 - val_accuracy: 0.0010\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9355 - accuracy: 0.0012 - val_loss: 0.9322 - val_accuracy: 0.0010\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9354 - accuracy: 0.0012 - val_loss: 0.9321 - val_accuracy: 0.0011\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9354 - accuracy: 0.0013 - val_loss: 0.9320 - val_accuracy: 0.0012\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9353 - accuracy: 0.0013 - val_loss: 0.9320 - val_accuracy: 0.0013\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9352 - accuracy: 0.0014 - val_loss: 0.9319 - val_accuracy: 0.0013\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9351 - accuracy: 0.0014 - val_loss: 0.9319 - val_accuracy: 0.0013\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9350 - accuracy: 0.0015 - val_loss: 0.9318 - val_accuracy: 0.0013\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9350 - accuracy: 0.0015 - val_loss: 0.9317 - val_accuracy: 0.0013\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9349 - accuracy: 0.0016 - val_loss: 0.9317 - val_accuracy: 0.0014\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9348 - accuracy: 0.0016 - val_loss: 0.9316 - val_accuracy: 0.0014\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9348 - accuracy: 0.0017 - val_loss: 0.9316 - val_accuracy: 0.0014\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9347 - accuracy: 0.0017 - val_loss: 0.9315 - val_accuracy: 0.0015\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9346 - accuracy: 0.0018 - val_loss: 0.9315 - val_accuracy: 0.0015\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9345 - accuracy: 0.0018 - val_loss: 0.9314 - val_accuracy: 0.0015\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9345 - accuracy: 0.0019 - val_loss: 0.9314 - val_accuracy: 0.0016\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9344 - accuracy: 0.0019 - val_loss: 0.9313 - val_accuracy: 0.0016\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9344 - accuracy: 0.0020 - val_loss: 0.9313 - val_accuracy: 0.0017\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9343 - accuracy: 0.0020 - val_loss: 0.9312 - val_accuracy: 0.0018\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9342 - accuracy: 0.0021 - val_loss: 0.9312 - val_accuracy: 0.0018\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9342 - accuracy: 0.0021 - val_loss: 0.9312 - val_accuracy: 0.0019\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9341 - accuracy: 0.0022 - val_loss: 0.9311 - val_accuracy: 0.0019\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9341 - accuracy: 0.0022 - val_loss: 0.9311 - val_accuracy: 0.0021\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9340 - accuracy: 0.0023 - val_loss: 0.9310 - val_accuracy: 0.0021\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9339 - accuracy: 0.0024 - val_loss: 0.9310 - val_accuracy: 0.0021\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9339 - accuracy: 0.0024 - val_loss: 0.9309 - val_accuracy: 0.0022\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9338 - accuracy: 0.0025 - val_loss: 0.9309 - val_accuracy: 0.0022\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9338 - accuracy: 0.0025 - val_loss: 0.9309 - val_accuracy: 0.0023\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9337 - accuracy: 0.0026 - val_loss: 0.9308 - val_accuracy: 0.0023\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9337 - accuracy: 0.0026 - val_loss: 0.9308 - val_accuracy: 0.0023\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9336 - accuracy: 0.0027 - val_loss: 0.9308 - val_accuracy: 0.0024\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9336 - accuracy: 0.0027 - val_loss: 0.9307 - val_accuracy: 0.0025\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9335 - accuracy: 0.0028 - val_loss: 0.9307 - val_accuracy: 0.0026\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9335 - accuracy: 0.0028 - val_loss: 0.9306 - val_accuracy: 0.0026\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9334 - accuracy: 0.0029 - val_loss: 0.9306 - val_accuracy: 0.0027\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9334 - accuracy: 0.0030 - val_loss: 0.9306 - val_accuracy: 0.0026\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9333 - accuracy: 0.0030 - val_loss: 0.9305 - val_accuracy: 0.0027\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9333 - accuracy: 0.0031 - val_loss: 0.9305 - val_accuracy: 0.0027\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9332 - accuracy: 0.0031 - val_loss: 0.9305 - val_accuracy: 0.0029\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9332 - accuracy: 0.0032 - val_loss: 0.9304 - val_accuracy: 0.0028\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9332 - accuracy: 0.0032 - val_loss: 0.9304 - val_accuracy: 0.0029\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9331 - accuracy: 0.0033 - val_loss: 0.9304 - val_accuracy: 0.0030\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9331 - accuracy: 0.0034 - val_loss: 0.9303 - val_accuracy: 0.0029\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9330 - accuracy: 0.0034 - val_loss: 0.9303 - val_accuracy: 0.0031\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9330 - accuracy: 0.0034 - val_loss: 0.9303 - val_accuracy: 0.0031\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9330 - accuracy: 0.0035 - val_loss: 0.9302 - val_accuracy: 0.0031\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9329 - accuracy: 0.0036 - val_loss: 0.9302 - val_accuracy: 0.0032\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9329 - accuracy: 0.0036 - val_loss: 0.9302 - val_accuracy: 0.0033\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9328 - accuracy: 0.0037 - val_loss: 0.9302 - val_accuracy: 0.0033\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9328 - accuracy: 0.0037 - val_loss: 0.9301 - val_accuracy: 0.0034\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9328 - accuracy: 0.0038 - val_loss: 0.9301 - val_accuracy: 0.0036\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9327 - accuracy: 0.0038 - val_loss: 0.9301 - val_accuracy: 0.0036\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9327 - accuracy: 0.0039 - val_loss: 0.9300 - val_accuracy: 0.0036\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9326 - accuracy: 0.0039 - val_loss: 0.9300 - val_accuracy: 0.0037\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9326 - accuracy: 0.0040 - val_loss: 0.9300 - val_accuracy: 0.0038\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9326 - accuracy: 0.0041 - val_loss: 0.9300 - val_accuracy: 0.0038\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9325 - accuracy: 0.0041 - val_loss: 0.9299 - val_accuracy: 0.0040\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9325 - accuracy: 0.0042 - val_loss: 0.9299 - val_accuracy: 0.0039\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9325 - accuracy: 0.0042 - val_loss: 0.9299 - val_accuracy: 0.0040\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9324 - accuracy: 0.0043 - val_loss: 0.9299 - val_accuracy: 0.0040\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9324 - accuracy: 0.0044 - val_loss: 0.9298 - val_accuracy: 0.0041\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9324 - accuracy: 0.0044 - val_loss: 0.9298 - val_accuracy: 0.0041\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9323 - accuracy: 0.0045 - val_loss: 0.9298 - val_accuracy: 0.0043\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9323 - accuracy: 0.0045 - val_loss: 0.9298 - val_accuracy: 0.0044\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9323 - accuracy: 0.0046 - val_loss: 0.9297 - val_accuracy: 0.0043\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9322 - accuracy: 0.0046 - val_loss: 0.9297 - val_accuracy: 0.0044\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9322 - accuracy: 0.0047 - val_loss: 0.9297 - val_accuracy: 0.0044\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9322 - accuracy: 0.0047 - val_loss: 0.9297 - val_accuracy: 0.0045\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9321 - accuracy: 0.0048 - val_loss: 0.9296 - val_accuracy: 0.0045\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9321 - accuracy: 0.0049 - val_loss: 0.9296 - val_accuracy: 0.0045\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9321 - accuracy: 0.0049 - val_loss: 0.9296 - val_accuracy: 0.0046\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9320 - accuracy: 0.0050 - val_loss: 0.9296 - val_accuracy: 0.0046\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9320 - accuracy: 0.0051 - val_loss: 0.9295 - val_accuracy: 0.0046\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9320 - accuracy: 0.0051 - val_loss: 0.9295 - val_accuracy: 0.0047\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9319 - accuracy: 0.0052 - val_loss: 0.9295 - val_accuracy: 0.0047\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9319 - accuracy: 0.0052 - val_loss: 0.9295 - val_accuracy: 0.0048\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9319 - accuracy: 0.0053 - val_loss: 0.9294 - val_accuracy: 0.0049\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9319 - accuracy: 0.0053 - val_loss: 0.9294 - val_accuracy: 0.0049\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9318 - accuracy: 0.0054 - val_loss: 0.9294 - val_accuracy: 0.0049\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9318 - accuracy: 0.0054 - val_loss: 0.9294 - val_accuracy: 0.0050\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9318 - accuracy: 0.0055 - val_loss: 0.9294 - val_accuracy: 0.0051\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9317 - accuracy: 0.0056 - val_loss: 0.9293 - val_accuracy: 0.0051\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9317 - accuracy: 0.0056 - val_loss: 0.9293 - val_accuracy: 0.0051\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9317 - accuracy: 0.0056 - val_loss: 0.9293 - val_accuracy: 0.0052\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9317 - accuracy: 0.0057 - val_loss: 0.9293 - val_accuracy: 0.0052\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.0057 - val_loss: 0.9293 - val_accuracy: 0.0053\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.0058 - val_loss: 0.9292 - val_accuracy: 0.0054\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.0059 - val_loss: 0.9292 - val_accuracy: 0.0054\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.0059 - val_loss: 0.9292 - val_accuracy: 0.0055\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9315 - accuracy: 0.0060 - val_loss: 0.9292 - val_accuracy: 0.0055\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9315 - accuracy: 0.0060 - val_loss: 0.9291 - val_accuracy: 0.0055\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9315 - accuracy: 0.0061 - val_loss: 0.9291 - val_accuracy: 0.0057\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9315 - accuracy: 0.0061 - val_loss: 0.9291 - val_accuracy: 0.0057\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9314 - accuracy: 0.0062 - val_loss: 0.9291 - val_accuracy: 0.0058\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9314 - accuracy: 0.0063 - val_loss: 0.9291 - val_accuracy: 0.0058\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9314 - accuracy: 0.0063 - val_loss: 0.9291 - val_accuracy: 0.0059\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9314 - accuracy: 0.0064 - val_loss: 0.9290 - val_accuracy: 0.0059\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9313 - accuracy: 0.0065 - val_loss: 0.9290 - val_accuracy: 0.0060\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9313 - accuracy: 0.0065 - val_loss: 0.9290 - val_accuracy: 0.0060\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9313 - accuracy: 0.0066 - val_loss: 0.9290 - val_accuracy: 0.0060\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9313 - accuracy: 0.0065 - val_loss: 0.9290 - val_accuracy: 0.0062\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9312 - accuracy: 0.0066 - val_loss: 0.9289 - val_accuracy: 0.0063\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9312 - accuracy: 0.0066 - val_loss: 0.9289 - val_accuracy: 0.0063\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9312 - accuracy: 0.0067 - val_loss: 0.9289 - val_accuracy: 0.0064\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9312 - accuracy: 0.0068 - val_loss: 0.9289 - val_accuracy: 0.0066\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9311 - accuracy: 0.0068 - val_loss: 0.9289 - val_accuracy: 0.0064\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9311 - accuracy: 0.0068 - val_loss: 0.9289 - val_accuracy: 0.0068\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9311 - accuracy: 0.0069 - val_loss: 0.9289 - val_accuracy: 0.0068\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9311 - accuracy: 0.0070 - val_loss: 0.9288 - val_accuracy: 0.0066\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.0070 - val_loss: 0.9288 - val_accuracy: 0.0068\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.0071 - val_loss: 0.9288 - val_accuracy: 0.0070\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.0071 - val_loss: 0.9288 - val_accuracy: 0.0070\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.0072 - val_loss: 0.9288 - val_accuracy: 0.0071\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.0072 - val_loss: 0.9287 - val_accuracy: 0.0072\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9309 - accuracy: 0.0073 - val_loss: 0.9287 - val_accuracy: 0.0071\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9309 - accuracy: 0.0073 - val_loss: 0.9287 - val_accuracy: 0.0072\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9303 - accuracy: 0.0077\n",
            "first layer: 150, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 0.0828 - accuracy: 0.0024 - val_loss: 0.0291 - val_accuracy: 0.0076\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.0116 - val_loss: 0.0229 - val_accuracy: 0.0183\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.0231 - val_loss: 0.0221 - val_accuracy: 0.0306\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.0324 - val_loss: 0.0199 - val_accuracy: 0.0410\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0173 - accuracy: 0.0404 - val_loss: 0.0205 - val_accuracy: 0.0432\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.0463 - val_loss: 0.0187 - val_accuracy: 0.0520\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0149 - accuracy: 0.0524 - val_loss: 0.0189 - val_accuracy: 0.0575\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.0559 - val_loss: 0.0250 - val_accuracy: 0.0577\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 0.0625 - val_loss: 0.0199 - val_accuracy: 0.0652\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.0656 - val_loss: 0.0190 - val_accuracy: 0.0746\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.0686 - val_loss: 0.0221 - val_accuracy: 0.0680\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.0709 - val_loss: 0.0220 - val_accuracy: 0.0709\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.0777 - val_loss: 0.0246 - val_accuracy: 0.0800\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.0820 - val_loss: 0.0207 - val_accuracy: 0.0852\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.0811 - val_loss: 0.0261 - val_accuracy: 0.0952\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.0865 - val_loss: 0.0220 - val_accuracy: 0.0830\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.0923 - val_loss: 0.0221 - val_accuracy: 0.0926\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.0935 - val_loss: 0.0246 - val_accuracy: 0.0944\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.1025 - val_loss: 0.0263 - val_accuracy: 0.1035\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.1081 - val_loss: 0.0231 - val_accuracy: 0.1128\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.1276 - val_loss: 0.0239 - val_accuracy: 0.1471\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.1543 - val_loss: 0.0279 - val_accuracy: 0.1923\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.1644 - val_loss: 0.0232 - val_accuracy: 0.1505\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.1666 - val_loss: 0.0307 - val_accuracy: 0.1800\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.1683 - val_loss: 0.0289 - val_accuracy: 0.2297\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.2114 - val_loss: 0.0273 - val_accuracy: 0.1777\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.2115 - val_loss: 0.0312 - val_accuracy: 0.2429\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.2308 - val_loss: 0.0282 - val_accuracy: 0.2565\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.2370 - val_loss: 0.0299 - val_accuracy: 0.2270\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.2592 - val_loss: 0.0361 - val_accuracy: 0.2584\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.2832 - val_loss: 0.0309 - val_accuracy: 0.3016\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.3250 - val_loss: 0.0297 - val_accuracy: 0.3570\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.3021 - val_loss: 0.0321 - val_accuracy: 0.3322\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.3340 - val_loss: 0.0381 - val_accuracy: 0.3101\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.3412 - val_loss: 0.0433 - val_accuracy: 0.3721\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.3682 - val_loss: 0.0409 - val_accuracy: 0.3420\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.3736 - val_loss: 0.0348 - val_accuracy: 0.4023\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.4077 - val_loss: 0.0453 - val_accuracy: 0.4521\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.4190 - val_loss: 0.0480 - val_accuracy: 0.4132\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.4234 - val_loss: 0.0380 - val_accuracy: 0.4408\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.4487 - val_loss: 0.0417 - val_accuracy: 0.4850\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.4558 - val_loss: 0.0416 - val_accuracy: 0.4481\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.4747 - val_loss: 0.0448 - val_accuracy: 0.4910\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.4805 - val_loss: 0.0394 - val_accuracy: 0.5064\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.5000 - val_loss: 0.0368 - val_accuracy: 0.4963\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.4764 - val_loss: 0.0438 - val_accuracy: 0.5093\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.5012 - val_loss: 0.0399 - val_accuracy: 0.5534\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.5400 - val_loss: 0.0463 - val_accuracy: 0.5876\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.5556 - val_loss: 0.0567 - val_accuracy: 0.5670\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.5459 - val_loss: 0.0517 - val_accuracy: 0.5804\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.5606 - val_loss: 0.0521 - val_accuracy: 0.5474\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.5662 - val_loss: 0.0443 - val_accuracy: 0.5584\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.5506 - val_loss: 0.0425 - val_accuracy: 0.5393\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.5488 - val_loss: 0.0551 - val_accuracy: 0.5972\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.6080 - val_loss: 0.0522 - val_accuracy: 0.6065\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.5895 - val_loss: 0.0486 - val_accuracy: 0.5803\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.6311 - val_loss: 0.0624 - val_accuracy: 0.6210\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.6182 - val_loss: 0.0573 - val_accuracy: 0.6046\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.5927 - val_loss: 0.0471 - val_accuracy: 0.5623\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.6222 - val_loss: 0.0421 - val_accuracy: 0.5191\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.6061 - val_loss: 0.0517 - val_accuracy: 0.6293\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.6539 - val_loss: 0.0621 - val_accuracy: 0.6785\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.6670 - val_loss: 0.0523 - val_accuracy: 0.6762\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.6702 - val_loss: 0.0572 - val_accuracy: 0.6690\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.6479 - val_loss: 0.0540 - val_accuracy: 0.6858\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.6560 - val_loss: 0.0586 - val_accuracy: 0.6971\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.7143 - val_loss: 0.0712 - val_accuracy: 0.7502\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.7054 - val_loss: 0.0882 - val_accuracy: 0.7078\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.6840 - val_loss: 0.0565 - val_accuracy: 0.6809\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.7364 - val_loss: 0.0631 - val_accuracy: 0.7631\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.7127 - val_loss: 0.0821 - val_accuracy: 0.6656\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.7072 - val_loss: 0.0652 - val_accuracy: 0.7646\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7162 - val_loss: 0.0815 - val_accuracy: 0.7815\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.7689 - val_loss: 0.0629 - val_accuracy: 0.7734\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.7758 - val_loss: 0.0709 - val_accuracy: 0.8003\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.7700 - val_loss: 0.0734 - val_accuracy: 0.7861\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.7830 - val_loss: 0.0763 - val_accuracy: 0.8129\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.7686 - val_loss: 0.0681 - val_accuracy: 0.7963\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.7652 - val_loss: 0.0621 - val_accuracy: 0.7700\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.7780 - val_loss: 0.0580 - val_accuracy: 0.7543\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.7830 - val_loss: 0.0828 - val_accuracy: 0.7668\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.7643 - val_loss: 0.0741 - val_accuracy: 0.7926\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.7732 - val_loss: 0.0814 - val_accuracy: 0.8064\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7963 - val_loss: 0.0643 - val_accuracy: 0.8087\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.8251 - val_loss: 0.0928 - val_accuracy: 0.8174\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.8010 - val_loss: 0.0768 - val_accuracy: 0.7966\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.8281 - val_loss: 0.0870 - val_accuracy: 0.8487\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8260 - val_loss: 0.0812 - val_accuracy: 0.8166\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.8124 - val_loss: 0.0792 - val_accuracy: 0.8145\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7863 - val_loss: 0.0914 - val_accuracy: 0.8221\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.8145 - val_loss: 0.0795 - val_accuracy: 0.8548\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.8337 - val_loss: 0.0836 - val_accuracy: 0.7805\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.8138 - val_loss: 0.0883 - val_accuracy: 0.8320\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.8273 - val_loss: 0.0967 - val_accuracy: 0.8802\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.8435 - val_loss: 0.0964 - val_accuracy: 0.8359\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.8572 - val_loss: 0.1014 - val_accuracy: 0.8515\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.8489 - val_loss: 0.0933 - val_accuracy: 0.8373\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.8337 - val_loss: 0.0888 - val_accuracy: 0.8338\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.8524 - val_loss: 0.0765 - val_accuracy: 0.8517\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.8547 - val_loss: 0.0947 - val_accuracy: 0.8401\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.8529 - val_loss: 0.0824 - val_accuracy: 0.8396\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.8518 - val_loss: 0.0767 - val_accuracy: 0.8224\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.8426 - val_loss: 0.0906 - val_accuracy: 0.8551\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.8438 - val_loss: 0.0877 - val_accuracy: 0.8335\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.8387 - val_loss: 0.0978 - val_accuracy: 0.8454\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.8464 - val_loss: 0.0961 - val_accuracy: 0.8709\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.8751 - val_loss: 0.0932 - val_accuracy: 0.8627\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.8749 - val_loss: 0.0874 - val_accuracy: 0.8334\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.8619 - val_loss: 0.1009 - val_accuracy: 0.8716\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.8674 - val_loss: 0.0955 - val_accuracy: 0.8757\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.8814 - val_loss: 0.1000 - val_accuracy: 0.8533\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.8785 - val_loss: 0.0983 - val_accuracy: 0.8632\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.8866 - val_loss: 0.1306 - val_accuracy: 0.8878\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.8929 - val_loss: 0.1257 - val_accuracy: 0.8922\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9002 - val_loss: 0.1277 - val_accuracy: 0.8706\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.8794 - val_loss: 0.1054 - val_accuracy: 0.8659\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.8932 - val_loss: 0.1342 - val_accuracy: 0.9246\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9025 - val_loss: 0.1292 - val_accuracy: 0.9209\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9122 - val_loss: 0.0860 - val_accuracy: 0.8613\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.8896 - val_loss: 0.1073 - val_accuracy: 0.9039\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9008 - val_loss: 0.1125 - val_accuracy: 0.9048\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.8902 - val_loss: 0.1101 - val_accuracy: 0.8762\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9114 - val_loss: 0.1290 - val_accuracy: 0.9083\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9176 - val_loss: 0.1351 - val_accuracy: 0.9043\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0159 - accuracy: 0.8793 - val_loss: 0.1075 - val_accuracy: 0.8936\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9010 - val_loss: 0.1430 - val_accuracy: 0.9180\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9098 - val_loss: 0.1260 - val_accuracy: 0.9216\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9205 - val_loss: 0.1204 - val_accuracy: 0.8927\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9238 - val_loss: 0.1173 - val_accuracy: 0.9193\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9201 - val_loss: 0.1082 - val_accuracy: 0.8897\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9187 - val_loss: 0.1117 - val_accuracy: 0.9061\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9198 - val_loss: 0.1141 - val_accuracy: 0.9269\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.9219 - val_loss: 0.1078 - val_accuracy: 0.8829\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9112 - val_loss: 0.1018 - val_accuracy: 0.9108\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9256 - val_loss: 0.1460 - val_accuracy: 0.9273\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9248 - val_loss: 0.1533 - val_accuracy: 0.9093\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.9218 - val_loss: 0.1255 - val_accuracy: 0.9290\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9273 - val_loss: 0.1524 - val_accuracy: 0.9324\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9330 - val_loss: 0.1370 - val_accuracy: 0.9291\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9375 - val_loss: 0.1394 - val_accuracy: 0.9414\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9507 - val_loss: 0.1298 - val_accuracy: 0.9227\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9240 - val_loss: 0.1149 - val_accuracy: 0.9188\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9363 - val_loss: 0.1300 - val_accuracy: 0.9277\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9366 - val_loss: 0.1571 - val_accuracy: 0.9212\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9150 - val_loss: 0.1062 - val_accuracy: 0.9030\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9343 - val_loss: 0.1556 - val_accuracy: 0.9090\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9372 - val_loss: 0.1765 - val_accuracy: 0.9368\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9319 - val_loss: 0.1373 - val_accuracy: 0.9046\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.9276 - val_loss: 0.1278 - val_accuracy: 0.8942\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9164 - val_loss: 0.1058 - val_accuracy: 0.9126\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9367 - val_loss: 0.1182 - val_accuracy: 0.9297\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9298 - val_loss: 0.1064 - val_accuracy: 0.9218\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9375 - val_loss: 0.1438 - val_accuracy: 0.9186\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9402 - val_loss: 0.1435 - val_accuracy: 0.9117\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9328 - val_loss: 0.1502 - val_accuracy: 0.9143\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9290 - val_loss: 0.1365 - val_accuracy: 0.9268\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9190 - val_loss: 0.1377 - val_accuracy: 0.9307\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9265 - val_loss: 0.1227 - val_accuracy: 0.9010\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9374 - val_loss: 0.1246 - val_accuracy: 0.9401\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9438 - val_loss: 0.1215 - val_accuracy: 0.9188\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9441 - val_loss: 0.1381 - val_accuracy: 0.9472\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9461 - val_loss: 0.1148 - val_accuracy: 0.9271\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9445 - val_loss: 0.1380 - val_accuracy: 0.9423\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9484 - val_loss: 0.1313 - val_accuracy: 0.9380\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9451 - val_loss: 0.1582 - val_accuracy: 0.9368\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9469 - val_loss: 0.1982 - val_accuracy: 0.9373\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9417 - val_loss: 0.1177 - val_accuracy: 0.9152\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9271 - val_loss: 0.1276 - val_accuracy: 0.9127\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9318 - val_loss: 0.1286 - val_accuracy: 0.9270\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9434 - val_loss: 0.1261 - val_accuracy: 0.9295\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9442 - val_loss: 0.1706 - val_accuracy: 0.9363\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9404 - val_loss: 0.1479 - val_accuracy: 0.9423\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9471 - val_loss: 0.1631 - val_accuracy: 0.9370\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.9417 - val_loss: 0.1712 - val_accuracy: 0.9198\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9413 - val_loss: 0.1457 - val_accuracy: 0.9007\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9204 - val_loss: 0.1243 - val_accuracy: 0.9296\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9528 - val_loss: 0.2033 - val_accuracy: 0.9528\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9489 - val_loss: 0.1985 - val_accuracy: 0.9434\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9474 - val_loss: 0.2250 - val_accuracy: 0.9391\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9440 - val_loss: 0.2000 - val_accuracy: 0.9323\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9453 - val_loss: 0.1679 - val_accuracy: 0.9309\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9333 - val_loss: 0.1794 - val_accuracy: 0.9333\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9449 - val_loss: 0.1879 - val_accuracy: 0.9401\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9565 - val_loss: 0.2028 - val_accuracy: 0.9429\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9515 - val_loss: 0.1817 - val_accuracy: 0.9333\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9536 - val_loss: 0.2012 - val_accuracy: 0.9359\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9276 - val_loss: 0.1882 - val_accuracy: 0.9276\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9393 - val_loss: 0.1864 - val_accuracy: 0.9226\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9515 - val_loss: 0.1845 - val_accuracy: 0.9456\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9508 - val_loss: 0.1843 - val_accuracy: 0.9262\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9506 - val_loss: 0.1736 - val_accuracy: 0.9374\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9497 - val_loss: 0.1888 - val_accuracy: 0.9441\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9402 - val_loss: 0.1905 - val_accuracy: 0.9405\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9489 - val_loss: 0.1921 - val_accuracy: 0.9355\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9455 - val_loss: 0.2168 - val_accuracy: 0.9436\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9566 - val_loss: 0.2068 - val_accuracy: 0.9381\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9580 - val_loss: 0.2233 - val_accuracy: 0.9390\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9503 - val_loss: 0.2295 - val_accuracy: 0.9163\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9399 - val_loss: 0.1755 - val_accuracy: 0.9373\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.9421 - val_loss: 0.1182 - val_accuracy: 0.9073\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.8978\n",
            "first layer: 200, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 6ms/step - loss: 1.0794 - accuracy: 0.0000e+00 - val_loss: 1.0790 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0784 - accuracy: 0.0000e+00 - val_loss: 1.0777 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0769 - accuracy: 0.0000e+00 - val_loss: 1.0758 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0745 - accuracy: 0.0000e+00 - val_loss: 1.0725 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0703 - accuracy: 0.0000e+00 - val_loss: 1.0673 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0648 - accuracy: 0.0000e+00 - val_loss: 1.0615 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0593 - accuracy: 0.0000e+00 - val_loss: 1.0561 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0542 - accuracy: 0.0000e+00 - val_loss: 1.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0493 - accuracy: 0.0000e+00 - val_loss: 1.0462 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0446 - accuracy: 0.0000e+00 - val_loss: 1.0413 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0397 - accuracy: 0.0000e+00 - val_loss: 1.0357 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0342 - accuracy: 0.0000e+00 - val_loss: 1.0296 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0280 - accuracy: 0.0000e+00 - val_loss: 1.0224 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0204 - accuracy: 0.0000e+00 - val_loss: 1.0137 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0115 - accuracy: 0.0000e+00 - val_loss: 1.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0026 - accuracy: 0.0000e+00 - val_loss: 0.9959 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9957 - accuracy: 0.0000e+00 - val_loss: 0.9894 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9898 - accuracy: 0.0000e+00 - val_loss: 0.9834 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9846 - accuracy: 0.0000e+00 - val_loss: 0.9784 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9804 - accuracy: 0.0000e+00 - val_loss: 0.9744 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9770 - accuracy: 0.0000e+00 - val_loss: 0.9712 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9742 - accuracy: 0.0000e+00 - val_loss: 0.9686 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9719 - accuracy: 0.0000e+00 - val_loss: 0.9665 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9699 - accuracy: 0.0000e+00 - val_loss: 0.9647 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9682 - accuracy: 0.0000e+00 - val_loss: 0.9631 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9668 - accuracy: 0.0000e+00 - val_loss: 0.9618 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9655 - accuracy: 0.0000e+00 - val_loss: 0.9607 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9644 - accuracy: 0.0000e+00 - val_loss: 0.9597 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9635 - accuracy: 0.0000e+00 - val_loss: 0.9589 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9626 - accuracy: 0.0000e+00 - val_loss: 0.9581 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9618 - accuracy: 0.0000e+00 - val_loss: 0.9574 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9611 - accuracy: 0.0000e+00 - val_loss: 0.9568 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9605 - accuracy: 0.0000e+00 - val_loss: 0.9563 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9599 - accuracy: 0.0000e+00 - val_loss: 0.9558 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9594 - accuracy: 0.0000e+00 - val_loss: 0.9553 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9589 - accuracy: 0.0000e+00 - val_loss: 0.9549 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9584 - accuracy: 0.0000e+00 - val_loss: 0.9546 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9580 - accuracy: 1.8519e-06 - val_loss: 0.9542 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9577 - accuracy: 1.8519e-06 - val_loss: 0.9539 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9573 - accuracy: 1.8519e-06 - val_loss: 0.9536 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9570 - accuracy: 1.8519e-06 - val_loss: 0.9534 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9567 - accuracy: 1.8519e-06 - val_loss: 0.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9564 - accuracy: 1.8519e-06 - val_loss: 0.9529 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9561 - accuracy: 3.7037e-06 - val_loss: 0.9527 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9558 - accuracy: 3.7037e-06 - val_loss: 0.9525 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9556 - accuracy: 5.5556e-06 - val_loss: 0.9522 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9554 - accuracy: 1.1111e-05 - val_loss: 0.9521 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9551 - accuracy: 1.2963e-05 - val_loss: 0.9519 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9549 - accuracy: 1.4815e-05 - val_loss: 0.9517 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9547 - accuracy: 1.2963e-05 - val_loss: 0.9516 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9546 - accuracy: 2.0370e-05 - val_loss: 0.9514 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9544 - accuracy: 2.7778e-05 - val_loss: 0.9513 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9542 - accuracy: 3.1481e-05 - val_loss: 0.9512 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9541 - accuracy: 4.8148e-05 - val_loss: 0.9510 - val_accuracy: 1.6667e-05\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9539 - accuracy: 6.2963e-05 - val_loss: 0.9509 - val_accuracy: 3.3333e-05\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9538 - accuracy: 7.0370e-05 - val_loss: 0.9508 - val_accuracy: 5.0000e-05\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9536 - accuracy: 8.8889e-05 - val_loss: 0.9507 - val_accuracy: 5.0000e-05\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9535 - accuracy: 1.0926e-04 - val_loss: 0.9506 - val_accuracy: 5.0000e-05\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9533 - accuracy: 1.1111e-04 - val_loss: 0.9505 - val_accuracy: 5.0000e-05\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9532 - accuracy: 1.2037e-04 - val_loss: 0.9504 - val_accuracy: 5.0000e-05\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9531 - accuracy: 1.4259e-04 - val_loss: 0.9503 - val_accuracy: 5.0000e-05\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9530 - accuracy: 1.6481e-04 - val_loss: 0.9502 - val_accuracy: 5.0000e-05\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9529 - accuracy: 1.7222e-04 - val_loss: 0.9501 - val_accuracy: 5.0000e-05\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9528 - accuracy: 1.8148e-04 - val_loss: 0.9500 - val_accuracy: 5.0000e-05\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9526 - accuracy: 2.2407e-04 - val_loss: 0.9499 - val_accuracy: 5.0000e-05\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9525 - accuracy: 2.4074e-04 - val_loss: 0.9498 - val_accuracy: 8.3333e-05\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9524 - accuracy: 2.5370e-04 - val_loss: 0.9498 - val_accuracy: 8.3333e-05\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9523 - accuracy: 2.7593e-04 - val_loss: 0.9497 - val_accuracy: 8.3333e-05\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9523 - accuracy: 3.0556e-04 - val_loss: 0.9496 - val_accuracy: 8.3333e-05\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9522 - accuracy: 3.2593e-04 - val_loss: 0.9495 - val_accuracy: 1.0000e-04\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9521 - accuracy: 3.4630e-04 - val_loss: 0.9495 - val_accuracy: 1.3333e-04\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9520 - accuracy: 3.8333e-04 - val_loss: 0.9494 - val_accuracy: 1.6667e-04\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9519 - accuracy: 4.1667e-04 - val_loss: 0.9494 - val_accuracy: 1.8333e-04\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9518 - accuracy: 4.4444e-04 - val_loss: 0.9493 - val_accuracy: 2.0000e-04\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9518 - accuracy: 4.7963e-04 - val_loss: 0.9492 - val_accuracy: 2.5000e-04\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9517 - accuracy: 5.1296e-04 - val_loss: 0.9492 - val_accuracy: 2.5000e-04\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 5.5185e-04 - val_loss: 0.9491 - val_accuracy: 3.1667e-04\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9515 - accuracy: 5.8889e-04 - val_loss: 0.9491 - val_accuracy: 3.5000e-04\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9515 - accuracy: 6.0741e-04 - val_loss: 0.9490 - val_accuracy: 3.8333e-04\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9514 - accuracy: 6.3704e-04 - val_loss: 0.9489 - val_accuracy: 4.3333e-04\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9513 - accuracy: 6.8519e-04 - val_loss: 0.9489 - val_accuracy: 5.3333e-04\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.9513 - accuracy: 7.0926e-04 - val_loss: 0.9488 - val_accuracy: 5.5000e-04\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.9512 - accuracy: 7.4815e-04 - val_loss: 0.9488 - val_accuracy: 5.6667e-04\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9511 - accuracy: 7.5926e-04 - val_loss: 0.9487 - val_accuracy: 5.8333e-04\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9511 - accuracy: 8.0000e-04 - val_loss: 0.9487 - val_accuracy: 5.8333e-04\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9510 - accuracy: 8.2778e-04 - val_loss: 0.9486 - val_accuracy: 6.0000e-04\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9510 - accuracy: 8.4259e-04 - val_loss: 0.9486 - val_accuracy: 6.3333e-04\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9509 - accuracy: 9.1296e-04 - val_loss: 0.9486 - val_accuracy: 6.5000e-04\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9508 - accuracy: 9.3148e-04 - val_loss: 0.9485 - val_accuracy: 6.5000e-04\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9508 - accuracy: 9.5556e-04 - val_loss: 0.9485 - val_accuracy: 7.0000e-04\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9507 - accuracy: 0.0010 - val_loss: 0.9484 - val_accuracy: 6.8333e-04\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9507 - accuracy: 0.0010 - val_loss: 0.9484 - val_accuracy: 7.0000e-04\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9506 - accuracy: 0.0011 - val_loss: 0.9484 - val_accuracy: 7.5000e-04\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9506 - accuracy: 0.0011 - val_loss: 0.9483 - val_accuracy: 7.5000e-04\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9505 - accuracy: 0.0011 - val_loss: 0.9483 - val_accuracy: 7.8333e-04\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9505 - accuracy: 0.0012 - val_loss: 0.9482 - val_accuracy: 8.0000e-04\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9504 - accuracy: 0.0012 - val_loss: 0.9482 - val_accuracy: 8.5000e-04\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9504 - accuracy: 0.0013 - val_loss: 0.9482 - val_accuracy: 9.5000e-04\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9504 - accuracy: 0.0013 - val_loss: 0.9481 - val_accuracy: 0.0010\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9503 - accuracy: 0.0014 - val_loss: 0.9481 - val_accuracy: 0.0010\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9503 - accuracy: 0.0014 - val_loss: 0.9481 - val_accuracy: 0.0010\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9502 - accuracy: 0.0014 - val_loss: 0.9480 - val_accuracy: 0.0011\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9502 - accuracy: 0.0015 - val_loss: 0.9480 - val_accuracy: 0.0011\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9501 - accuracy: 0.0015 - val_loss: 0.9480 - val_accuracy: 0.0012\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9501 - accuracy: 0.0015 - val_loss: 0.9479 - val_accuracy: 0.0012\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9501 - accuracy: 0.0016 - val_loss: 0.9479 - val_accuracy: 0.0012\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9500 - accuracy: 0.0016 - val_loss: 0.9479 - val_accuracy: 0.0013\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9500 - accuracy: 0.0017 - val_loss: 0.9478 - val_accuracy: 0.0014\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9499 - accuracy: 0.0018 - val_loss: 0.9478 - val_accuracy: 0.0013\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9499 - accuracy: 0.0018 - val_loss: 0.9478 - val_accuracy: 0.0014\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9499 - accuracy: 0.0018 - val_loss: 0.9477 - val_accuracy: 0.0014\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9498 - accuracy: 0.0018 - val_loss: 0.9477 - val_accuracy: 0.0014\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9498 - accuracy: 0.0019 - val_loss: 0.9477 - val_accuracy: 0.0015\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9498 - accuracy: 0.0020 - val_loss: 0.9477 - val_accuracy: 0.0015\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9497 - accuracy: 0.0020 - val_loss: 0.9476 - val_accuracy: 0.0015\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9497 - accuracy: 0.0020 - val_loss: 0.9476 - val_accuracy: 0.0015\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9497 - accuracy: 0.0021 - val_loss: 0.9476 - val_accuracy: 0.0016\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9496 - accuracy: 0.0021 - val_loss: 0.9475 - val_accuracy: 0.0017\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9496 - accuracy: 0.0022 - val_loss: 0.9475 - val_accuracy: 0.0017\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9496 - accuracy: 0.0023 - val_loss: 0.9475 - val_accuracy: 0.0018\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9495 - accuracy: 0.0023 - val_loss: 0.9475 - val_accuracy: 0.0018\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9495 - accuracy: 0.0023 - val_loss: 0.9474 - val_accuracy: 0.0018\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9495 - accuracy: 0.0023 - val_loss: 0.9474 - val_accuracy: 0.0019\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9494 - accuracy: 0.0024 - val_loss: 0.9474 - val_accuracy: 0.0019\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9494 - accuracy: 0.0025 - val_loss: 0.9474 - val_accuracy: 0.0019\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9494 - accuracy: 0.0025 - val_loss: 0.9474 - val_accuracy: 0.0020\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9493 - accuracy: 0.0026 - val_loss: 0.9473 - val_accuracy: 0.0019\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9493 - accuracy: 0.0026 - val_loss: 0.9473 - val_accuracy: 0.0021\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9493 - accuracy: 0.0027 - val_loss: 0.9473 - val_accuracy: 0.0021\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9493 - accuracy: 0.0027 - val_loss: 0.9473 - val_accuracy: 0.0020\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9492 - accuracy: 0.0028 - val_loss: 0.9473 - val_accuracy: 0.0021\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9492 - accuracy: 0.0028 - val_loss: 0.9472 - val_accuracy: 0.0022\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9492 - accuracy: 0.0028 - val_loss: 0.9472 - val_accuracy: 0.0022\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9492 - accuracy: 0.0029 - val_loss: 0.9472 - val_accuracy: 0.0023\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9491 - accuracy: 0.0030 - val_loss: 0.9472 - val_accuracy: 0.0023\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9491 - accuracy: 0.0030 - val_loss: 0.9471 - val_accuracy: 0.0025\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9491 - accuracy: 0.0030 - val_loss: 0.9471 - val_accuracy: 0.0025\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9490 - accuracy: 0.0031 - val_loss: 0.9471 - val_accuracy: 0.0024\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9490 - accuracy: 0.0031 - val_loss: 0.9471 - val_accuracy: 0.0026\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9490 - accuracy: 0.0032 - val_loss: 0.9471 - val_accuracy: 0.0026\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9490 - accuracy: 0.0032 - val_loss: 0.9470 - val_accuracy: 0.0026\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.0032 - val_loss: 0.9470 - val_accuracy: 0.0027\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.0033 - val_loss: 0.9470 - val_accuracy: 0.0027\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.0033 - val_loss: 0.9470 - val_accuracy: 0.0026\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.0033 - val_loss: 0.9470 - val_accuracy: 0.0027\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.0034 - val_loss: 0.9470 - val_accuracy: 0.0027\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.0034 - val_loss: 0.9469 - val_accuracy: 0.0028\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.0035 - val_loss: 0.9469 - val_accuracy: 0.0030\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.0035 - val_loss: 0.9469 - val_accuracy: 0.0030\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.0036 - val_loss: 0.9469 - val_accuracy: 0.0030\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9487 - accuracy: 0.0036 - val_loss: 0.9469 - val_accuracy: 0.0030\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9487 - accuracy: 0.0036 - val_loss: 0.9468 - val_accuracy: 0.0031\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9487 - accuracy: 0.0037 - val_loss: 0.9468 - val_accuracy: 0.0032\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9487 - accuracy: 0.0038 - val_loss: 0.9468 - val_accuracy: 0.0032\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9487 - accuracy: 0.0038 - val_loss: 0.9468 - val_accuracy: 0.0033\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9486 - accuracy: 0.0038 - val_loss: 0.9468 - val_accuracy: 0.0034\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9486 - accuracy: 0.0039 - val_loss: 0.9468 - val_accuracy: 0.0034\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9486 - accuracy: 0.0039 - val_loss: 0.9467 - val_accuracy: 0.0035\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9486 - accuracy: 0.0040 - val_loss: 0.9467 - val_accuracy: 0.0035\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.0040 - val_loss: 0.9467 - val_accuracy: 0.0036\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.0041 - val_loss: 0.9467 - val_accuracy: 0.0037\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.0041 - val_loss: 0.9467 - val_accuracy: 0.0037\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.0042 - val_loss: 0.9467 - val_accuracy: 0.0038\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.0042 - val_loss: 0.9466 - val_accuracy: 0.0038\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.0042 - val_loss: 0.9466 - val_accuracy: 0.0039\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.0043 - val_loss: 0.9466 - val_accuracy: 0.0038\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.0043 - val_loss: 0.9466 - val_accuracy: 0.0039\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.0044 - val_loss: 0.9466 - val_accuracy: 0.0039\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.0044 - val_loss: 0.9466 - val_accuracy: 0.0040\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.0044 - val_loss: 0.9465 - val_accuracy: 0.0041\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.0045 - val_loss: 0.9465 - val_accuracy: 0.0041\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.0046 - val_loss: 0.9465 - val_accuracy: 0.0041\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.0046 - val_loss: 0.9465 - val_accuracy: 0.0043\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.0046 - val_loss: 0.9465 - val_accuracy: 0.0043\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.0046 - val_loss: 0.9465 - val_accuracy: 0.0042\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.0047 - val_loss: 0.9465 - val_accuracy: 0.0044\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.0047 - val_loss: 0.9464 - val_accuracy: 0.0043\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.0048 - val_loss: 0.9464 - val_accuracy: 0.0043\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9481 - accuracy: 0.0048 - val_loss: 0.9464 - val_accuracy: 0.0043\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9481 - accuracy: 0.0048 - val_loss: 0.9463 - val_accuracy: 0.0044\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9481 - accuracy: 0.0048 - val_loss: 0.9463 - val_accuracy: 0.0044\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9480 - accuracy: 0.0049 - val_loss: 0.9462 - val_accuracy: 0.0044\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9479 - accuracy: 0.0048 - val_loss: 0.9461 - val_accuracy: 0.0044\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9477 - accuracy: 0.0048 - val_loss: 0.9455 - val_accuracy: 0.0042\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9463 - accuracy: 0.0045 - val_loss: 0.9421 - val_accuracy: 0.0036\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9424 - accuracy: 0.0032 - val_loss: 0.9382 - val_accuracy: 0.0020\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9406 - accuracy: 0.0024 - val_loss: 0.9369 - val_accuracy: 0.0016\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9396 - accuracy: 0.0022 - val_loss: 0.9361 - val_accuracy: 0.0016\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9388 - accuracy: 0.0022 - val_loss: 0.9353 - val_accuracy: 0.0018\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9381 - accuracy: 0.0022 - val_loss: 0.9347 - val_accuracy: 0.0017\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.9375 - accuracy: 0.0021 - val_loss: 0.9343 - val_accuracy: 0.0018\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9370 - accuracy: 0.0022 - val_loss: 0.9338 - val_accuracy: 0.0017\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9366 - accuracy: 0.0021 - val_loss: 0.9335 - val_accuracy: 0.0018\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9363 - accuracy: 0.0022 - val_loss: 0.9332 - val_accuracy: 0.0018\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9360 - accuracy: 0.0022 - val_loss: 0.9329 - val_accuracy: 0.0019\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9357 - accuracy: 0.0023 - val_loss: 0.9327 - val_accuracy: 0.0019\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9354 - accuracy: 0.0023 - val_loss: 0.9325 - val_accuracy: 0.0020\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9352 - accuracy: 0.0024 - val_loss: 0.9323 - val_accuracy: 0.0021\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9350 - accuracy: 0.0024 - val_loss: 0.9321 - val_accuracy: 0.0021\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.9348 - accuracy: 0.0025 - val_loss: 0.9320 - val_accuracy: 0.0021\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9337 - accuracy: 0.0024\n",
            "first layer: 200, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 6ms/step - loss: 0.0941 - accuracy: 0.0021 - val_loss: 0.0281 - val_accuracy: 0.0053\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0303 - accuracy: 0.0125 - val_loss: 0.0205 - val_accuracy: 0.0167\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.0244 - val_loss: 0.0195 - val_accuracy: 0.0343\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.0339 - val_loss: 0.0191 - val_accuracy: 0.0392\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.0418 - val_loss: 0.0200 - val_accuracy: 0.0403\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.0478 - val_loss: 0.0196 - val_accuracy: 0.0470\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.0551 - val_loss: 0.0210 - val_accuracy: 0.0549\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.0572 - val_loss: 0.0215 - val_accuracy: 0.0571\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.0631 - val_loss: 0.0201 - val_accuracy: 0.0671\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.0657 - val_loss: 0.0229 - val_accuracy: 0.0719\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.0702 - val_loss: 0.0201 - val_accuracy: 0.0756\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.0723 - val_loss: 0.0198 - val_accuracy: 0.0734\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.0764 - val_loss: 0.0264 - val_accuracy: 0.0769\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.0774 - val_loss: 0.0215 - val_accuracy: 0.0805\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.0810 - val_loss: 0.0225 - val_accuracy: 0.0808\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.0860 - val_loss: 0.0223 - val_accuracy: 0.0932\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.0960 - val_loss: 0.0211 - val_accuracy: 0.0967\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.1040 - val_loss: 0.0268 - val_accuracy: 0.0949\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.1012 - val_loss: 0.0236 - val_accuracy: 0.1107\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.1092 - val_loss: 0.0267 - val_accuracy: 0.1147\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.1154 - val_loss: 0.0245 - val_accuracy: 0.1249\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.1248 - val_loss: 0.0252 - val_accuracy: 0.1680\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.1614 - val_loss: 0.0254 - val_accuracy: 0.1510\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.1624 - val_loss: 0.0245 - val_accuracy: 0.1507\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.1658 - val_loss: 0.0304 - val_accuracy: 0.1757\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.1696 - val_loss: 0.0301 - val_accuracy: 0.1739\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.2121 - val_loss: 0.0287 - val_accuracy: 0.2289\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.2362 - val_loss: 0.0333 - val_accuracy: 0.2626\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.2715 - val_loss: 0.0342 - val_accuracy: 0.2281\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.2752 - val_loss: 0.0377 - val_accuracy: 0.3271\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.3018 - val_loss: 0.0301 - val_accuracy: 0.2738\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.3095 - val_loss: 0.0350 - val_accuracy: 0.3506\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.3521 - val_loss: 0.0379 - val_accuracy: 0.3520\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.3374 - val_loss: 0.0428 - val_accuracy: 0.3945\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.3840 - val_loss: 0.0401 - val_accuracy: 0.4093\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.4229 - val_loss: 0.0389 - val_accuracy: 0.4698\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.4312 - val_loss: 0.0354 - val_accuracy: 0.4195\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.4422 - val_loss: 0.0422 - val_accuracy: 0.3721\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.4193 - val_loss: 0.0306 - val_accuracy: 0.3725\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.4306 - val_loss: 0.0338 - val_accuracy: 0.4833\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.4654 - val_loss: 0.0313 - val_accuracy: 0.4655\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.4581 - val_loss: 0.0363 - val_accuracy: 0.5387\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.5148 - val_loss: 0.0476 - val_accuracy: 0.5386\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.5585 - val_loss: 0.0402 - val_accuracy: 0.4944\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.5688 - val_loss: 0.0422 - val_accuracy: 0.5517\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.6016 - val_loss: 0.0416 - val_accuracy: 0.6590\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.6093 - val_loss: 0.0455 - val_accuracy: 0.6125\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.6045 - val_loss: 0.0452 - val_accuracy: 0.5723\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.5990 - val_loss: 0.0580 - val_accuracy: 0.7117\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.6232 - val_loss: 0.0436 - val_accuracy: 0.5985\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.6011 - val_loss: 0.0447 - val_accuracy: 0.6401\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.6465 - val_loss: 0.0534 - val_accuracy: 0.6972\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.6305 - val_loss: 0.0508 - val_accuracy: 0.6414\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.6555 - val_loss: 0.0479 - val_accuracy: 0.6267\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.6555 - val_loss: 0.0546 - val_accuracy: 0.7121\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.7026 - val_loss: 0.0565 - val_accuracy: 0.7351\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.6933 - val_loss: 0.0448 - val_accuracy: 0.6664\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.7093 - val_loss: 0.0502 - val_accuracy: 0.7075\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.7269 - val_loss: 0.0455 - val_accuracy: 0.6845\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.7398 - val_loss: 0.0530 - val_accuracy: 0.7510\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7067 - val_loss: 0.0516 - val_accuracy: 0.6670\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.7046 - val_loss: 0.0519 - val_accuracy: 0.7702\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.7158 - val_loss: 0.0500 - val_accuracy: 0.7367\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.7303 - val_loss: 0.0438 - val_accuracy: 0.6992\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.7315 - val_loss: 0.0556 - val_accuracy: 0.7428\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.7541 - val_loss: 0.0484 - val_accuracy: 0.7577\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.7618 - val_loss: 0.0608 - val_accuracy: 0.7632\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.7553 - val_loss: 0.0614 - val_accuracy: 0.7390\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.7711 - val_loss: 0.0531 - val_accuracy: 0.7663\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.8019 - val_loss: 0.0552 - val_accuracy: 0.8236\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0094 - accuracy: 0.7968 - val_loss: 0.0618 - val_accuracy: 0.7990\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.8003 - val_loss: 0.0625 - val_accuracy: 0.7902\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.7989 - val_loss: 0.0571 - val_accuracy: 0.8090\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.8523 - val_loss: 0.0716 - val_accuracy: 0.8391\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.8159 - val_loss: 0.0684 - val_accuracy: 0.7905\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.8164 - val_loss: 0.0620 - val_accuracy: 0.8469\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.8428 - val_loss: 0.0610 - val_accuracy: 0.8261\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.8412 - val_loss: 0.0736 - val_accuracy: 0.8252\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.8287 - val_loss: 0.0599 - val_accuracy: 0.8272\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.8657 - val_loss: 0.0841 - val_accuracy: 0.8723\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.8577 - val_loss: 0.0655 - val_accuracy: 0.8493\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.8471 - val_loss: 0.0845 - val_accuracy: 0.7526\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.8307 - val_loss: 0.0700 - val_accuracy: 0.8207\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.8602 - val_loss: 0.0827 - val_accuracy: 0.8256\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.8380 - val_loss: 0.0873 - val_accuracy: 0.8558\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.8582 - val_loss: 0.0842 - val_accuracy: 0.8559\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.8762 - val_loss: 0.0824 - val_accuracy: 0.8131\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.8612 - val_loss: 0.0839 - val_accuracy: 0.8235\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.8523 - val_loss: 0.0882 - val_accuracy: 0.8550\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.8606 - val_loss: 0.0894 - val_accuracy: 0.8641\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.8809 - val_loss: 0.0703 - val_accuracy: 0.8632\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.8948 - val_loss: 0.1033 - val_accuracy: 0.8910\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9102 - val_loss: 0.0997 - val_accuracy: 0.8957\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.8945 - val_loss: 0.0870 - val_accuracy: 0.8967\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.8888 - val_loss: 0.0755 - val_accuracy: 0.8931\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9003 - val_loss: 0.0855 - val_accuracy: 0.9117\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9089 - val_loss: 0.0874 - val_accuracy: 0.8974\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9170 - val_loss: 0.0985 - val_accuracy: 0.9106\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9126 - val_loss: 0.0963 - val_accuracy: 0.8992\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9099 - val_loss: 0.0951 - val_accuracy: 0.9197\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9209 - val_loss: 0.1095 - val_accuracy: 0.8841\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.8993 - val_loss: 0.0769 - val_accuracy: 0.8780\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.8998 - val_loss: 0.1251 - val_accuracy: 0.8468\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.8773 - val_loss: 0.0994 - val_accuracy: 0.8967\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.8977 - val_loss: 0.1122 - val_accuracy: 0.8990\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.8955 - val_loss: 0.1023 - val_accuracy: 0.9214\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9232 - val_loss: 0.1079 - val_accuracy: 0.9154\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9031 - val_loss: 0.0956 - val_accuracy: 0.9073\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9125 - val_loss: 0.0956 - val_accuracy: 0.8652\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.8879 - val_loss: 0.0921 - val_accuracy: 0.8751\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9067 - val_loss: 0.1061 - val_accuracy: 0.9117\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9077 - val_loss: 0.1030 - val_accuracy: 0.9184\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9200 - val_loss: 0.1073 - val_accuracy: 0.8967\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9155 - val_loss: 0.1131 - val_accuracy: 0.9146\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9096 - val_loss: 0.1257 - val_accuracy: 0.9164\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9218 - val_loss: 0.1450 - val_accuracy: 0.9100\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9247 - val_loss: 0.1201 - val_accuracy: 0.8853\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0119 - accuracy: 0.9115 - val_loss: 0.1248 - val_accuracy: 0.9151\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9220 - val_loss: 0.1482 - val_accuracy: 0.9336\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9219 - val_loss: 0.1261 - val_accuracy: 0.9168\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9200 - val_loss: 0.1288 - val_accuracy: 0.9001\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9213 - val_loss: 0.1115 - val_accuracy: 0.9057\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0110 - accuracy: 0.9183 - val_loss: 0.1369 - val_accuracy: 0.9149\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9256 - val_loss: 0.1074 - val_accuracy: 0.9050\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9240 - val_loss: 0.1038 - val_accuracy: 0.9198\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9399 - val_loss: 0.1212 - val_accuracy: 0.9170\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9325 - val_loss: 0.1292 - val_accuracy: 0.8984\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9386 - val_loss: 0.1441 - val_accuracy: 0.9348\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9429 - val_loss: 0.1463 - val_accuracy: 0.9255\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9353 - val_loss: 0.1448 - val_accuracy: 0.9180\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9319 - val_loss: 0.1345 - val_accuracy: 0.9296\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9266 - val_loss: 0.1646 - val_accuracy: 0.9252\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9346 - val_loss: 0.1457 - val_accuracy: 0.8979\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9448 - val_loss: 0.1347 - val_accuracy: 0.9176\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9284 - val_loss: 0.1149 - val_accuracy: 0.9173\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9324 - val_loss: 0.0971 - val_accuracy: 0.9207\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9513 - val_loss: 0.1375 - val_accuracy: 0.9395\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9515 - val_loss: 0.1741 - val_accuracy: 0.9426\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9226 - val_loss: 0.1321 - val_accuracy: 0.9305\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9462 - val_loss: 0.1368 - val_accuracy: 0.9338\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9458 - val_loss: 0.1609 - val_accuracy: 0.9452\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9451 - val_loss: 0.1281 - val_accuracy: 0.9148\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9480 - val_loss: 0.1197 - val_accuracy: 0.9419\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9515 - val_loss: 0.1441 - val_accuracy: 0.9335\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9435 - val_loss: 0.1417 - val_accuracy: 0.9361\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9384 - val_loss: 0.1341 - val_accuracy: 0.9157\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9404 - val_loss: 0.1613 - val_accuracy: 0.9452\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9540 - val_loss: 0.1571 - val_accuracy: 0.9298\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9567 - val_loss: 0.1480 - val_accuracy: 0.9426\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9413 - val_loss: 0.1499 - val_accuracy: 0.9297\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9459 - val_loss: 0.1653 - val_accuracy: 0.9443\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9455 - val_loss: 0.1426 - val_accuracy: 0.9196\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9384 - val_loss: 0.1180 - val_accuracy: 0.9331\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9431 - val_loss: 0.1453 - val_accuracy: 0.9463\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9376 - val_loss: 0.1206 - val_accuracy: 0.9226\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9322 - val_loss: 0.1256 - val_accuracy: 0.9187\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9376 - val_loss: 0.1362 - val_accuracy: 0.9360\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9446 - val_loss: 0.1320 - val_accuracy: 0.9263\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9504 - val_loss: 0.1701 - val_accuracy: 0.9301\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.9412 - val_loss: 0.1414 - val_accuracy: 0.9385\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9463 - val_loss: 0.1286 - val_accuracy: 0.9328\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9244 - val_loss: 0.1509 - val_accuracy: 0.9147\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9511 - val_loss: 0.1461 - val_accuracy: 0.9237\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9394 - val_loss: 0.1269 - val_accuracy: 0.9318\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9326 - val_loss: 0.1241 - val_accuracy: 0.9385\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9575 - val_loss: 0.1662 - val_accuracy: 0.9475\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9521 - val_loss: 0.1457 - val_accuracy: 0.9480\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9653 - val_loss: 0.1346 - val_accuracy: 0.9365\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9548 - val_loss: 0.1760 - val_accuracy: 0.9397\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9545 - val_loss: 0.1375 - val_accuracy: 0.9342\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9608 - val_loss: 0.1748 - val_accuracy: 0.9549\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9617 - val_loss: 0.1713 - val_accuracy: 0.9317\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9538 - val_loss: 0.1561 - val_accuracy: 0.9379\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9485 - val_loss: 0.1387 - val_accuracy: 0.9305\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9439 - val_loss: 0.1636 - val_accuracy: 0.9447\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9351 - val_loss: 0.1567 - val_accuracy: 0.9286\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9454 - val_loss: 0.1659 - val_accuracy: 0.9315\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.9556 - val_loss: 0.1922 - val_accuracy: 0.9537\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9585 - val_loss: 0.1518 - val_accuracy: 0.9360\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.9530 - val_loss: 0.1303 - val_accuracy: 0.9268\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9510 - val_loss: 0.1290 - val_accuracy: 0.9370\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9535 - val_loss: 0.1402 - val_accuracy: 0.9477\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9584 - val_loss: 0.1800 - val_accuracy: 0.9443\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9608 - val_loss: 0.1731 - val_accuracy: 0.9314\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9562 - val_loss: 0.2572 - val_accuracy: 0.9465\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9483 - val_loss: 0.1457 - val_accuracy: 0.9149\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9491 - val_loss: 0.1707 - val_accuracy: 0.9346\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9549 - val_loss: 0.2174 - val_accuracy: 0.9438\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9662 - val_loss: 0.2090 - val_accuracy: 0.9473\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9615 - val_loss: 0.1909 - val_accuracy: 0.9472\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9566 - val_loss: 0.1787 - val_accuracy: 0.9352\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9440 - val_loss: 0.1932 - val_accuracy: 0.9437\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9553 - val_loss: 0.2236 - val_accuracy: 0.9377\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9509 - val_loss: 0.1719 - val_accuracy: 0.9491\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9543 - val_loss: 0.1748 - val_accuracy: 0.9320\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9610 - val_loss: 0.2339 - val_accuracy: 0.9481\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9637 - val_loss: 0.2035 - val_accuracy: 0.9413\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.9541 - val_loss: 0.2019 - val_accuracy: 0.9432\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9632 - val_loss: 0.2262 - val_accuracy: 0.9549\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9617 - val_loss: 0.1854 - val_accuracy: 0.9506\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9457\n"
          ]
        }
      ],
      "source": [
        "if device_name != '/device:GPU:0':  \n",
        "  model_builder2()\n",
        "else:\n",
        "    with tf.device('GPU:0'):\n",
        "        model_builder2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first layer: 150, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0478 - accuracy: 0.0173 - val_loss: 1.0000 - val_accuracy: 0.0195\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.0212 - val_loss: 1.0000 - val_accuracy: 0.0194\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.0212 - val_loss: 1.0000 - val_accuracy: 0.0194\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.0211 - val_loss: 1.0000 - val_accuracy: 0.0193\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.0211 - val_loss: 1.0000 - val_accuracy: 0.0197\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 6.7300 - accuracy: 0.7219 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8611 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.8610 - val_loss: 1.0000 - val_accuracy: 0.8617\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.8632\n",
            "first layer: 150, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 8ms/step - loss: 1.1037 - accuracy: 0.4109 - val_loss: 1.0000 - val_accuracy: 0.5723\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5721 - val_loss: 1.0000 - val_accuracy: 0.5723\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5720 - val_loss: 1.0000 - val_accuracy: 0.5721\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.5718 - val_loss: 1.0000 - val_accuracy: 0.5719\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5717 - val_loss: 1.0000 - val_accuracy: 0.5718\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5715 - val_loss: 1.0000 - val_accuracy: 0.5716\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5713 - val_loss: 1.0000 - val_accuracy: 0.5714\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5712 - val_loss: 1.0000 - val_accuracy: 0.5712\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5709 - val_loss: 1.0000 - val_accuracy: 0.5710\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5707 - val_loss: 1.0000 - val_accuracy: 0.5708\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5705 - val_loss: 1.0000 - val_accuracy: 0.5706\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5703 - val_loss: 1.0000 - val_accuracy: 0.5703\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5701 - val_loss: 1.0000 - val_accuracy: 0.5701\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5698 - val_loss: 1.0000 - val_accuracy: 0.5699\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5695 - val_loss: 1.0000 - val_accuracy: 0.5697\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5692 - val_loss: 1.0000 - val_accuracy: 0.5696\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5689 - val_loss: 1.0000 - val_accuracy: 0.5693\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5686 - val_loss: 1.0000 - val_accuracy: 0.5689\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5681 - val_loss: 1.0000 - val_accuracy: 0.5684\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5676 - val_loss: 1.0000 - val_accuracy: 0.5681\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5671 - val_loss: 1.0000 - val_accuracy: 0.5676\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5664 - val_loss: 1.0000 - val_accuracy: 0.5670\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.5652 - val_loss: 1.0000 - val_accuracy: 0.5657\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0797 - accuracy: 0.7334 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 2s 8ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8733 - val_loss: 1.0000 - val_accuracy: 0.8719\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0000 - accuracy: 0.8736\n",
            "first layer: 200, second layer 30\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.1378 - accuracy: 0.3268 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3912 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3890\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3892\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3892\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3893\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3893\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3915 - val_loss: 1.0000 - val_accuracy: 0.3894\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3915 - val_loss: 1.0000 - val_accuracy: 0.3893\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3915 - val_loss: 1.0000 - val_accuracy: 0.3893\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3892\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3914 - val_loss: 1.0000 - val_accuracy: 0.3892\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3913 - val_loss: 1.0000 - val_accuracy: 0.3891\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3911 - val_loss: 1.0000 - val_accuracy: 0.3889\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3908 - val_loss: 1.0000 - val_accuracy: 0.3885\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.3901 - val_loss: 1.0000 - val_accuracy: 0.3872\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 3.1752 - accuracy: 0.7944 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.9000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0000 - accuracy: 0.9000\n",
            "first layer: 200, second layer 50\n",
            "Epoch 1/200\n",
            "216/216 [==============================] - 2s 6ms/step - loss: 1.1888 - accuracy: 0.4281 - val_loss: 1.0000 - val_accuracy: 0.3715\n",
            "Epoch 2/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0499 - accuracy: 0.2807 - val_loss: 1.0000 - val_accuracy: 0.1819\n",
            "Epoch 3/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.1333 - accuracy: 0.5156 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 4/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 5/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 6/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 7/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 8/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 9/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 10/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 11/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 12/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 13/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 14/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 15/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 16/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 17/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 18/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 19/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 20/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 21/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 22/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 23/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 24/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 25/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 26/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 27/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 28/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 29/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 30/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 31/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 32/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 33/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 34/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 35/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 36/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 37/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 38/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 39/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 40/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 41/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 42/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 43/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 44/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 45/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 46/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 47/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 48/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 49/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 50/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 51/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 52/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 53/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 54/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 55/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 56/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 57/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 58/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 59/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 60/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 61/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 62/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 63/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 64/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 65/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 66/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 67/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 68/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 69/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 70/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 71/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 72/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 73/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 74/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 75/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 76/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 77/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 78/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 79/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 80/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 81/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 82/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 83/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 84/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 85/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 86/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 87/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 88/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 89/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 90/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 91/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 92/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 93/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 94/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 95/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 96/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 97/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 98/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 99/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 100/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 101/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 102/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 103/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 104/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 105/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 106/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 107/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 108/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 109/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 110/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 111/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 112/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 113/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 114/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 115/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 116/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 117/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 118/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 119/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 120/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 121/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 122/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 123/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 124/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 125/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 126/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 127/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 128/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 129/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 130/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 131/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 132/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 133/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 134/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 135/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 136/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 137/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 138/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 139/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 140/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 141/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 142/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 143/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 144/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 145/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 146/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 147/200\n",
            "216/216 [==============================] - 1s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 148/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 149/200\n",
            "216/216 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 150/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 151/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 152/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 153/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 154/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 155/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 156/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 157/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 158/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 159/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 160/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 161/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 162/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 163/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 164/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 165/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 166/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 167/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 168/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 169/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 170/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 171/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 172/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 173/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 174/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 175/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 176/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 177/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 178/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 179/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 180/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 181/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 182/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 183/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 184/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 185/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 186/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 187/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 188/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 189/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 190/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 191/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 192/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 193/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 194/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 195/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 196/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 197/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 198/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 199/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "Epoch 200/200\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 1.0000 - accuracy: 0.8434 - val_loss: 1.0000 - val_accuracy: 0.8467\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0000 - accuracy: 0.8478\n"
          ]
        }
      ],
      "source": [
        "if device_name != '/device:GPU:0':  \n",
        "  model_builder3()\n",
        "else:\n",
        "    with tf.device('GPU:0'):\n",
        "        model_builder3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HisIR0-mqim-"
      },
      "source": [
        "### Creating the dataframe that denotes all hyperparameters and their respective loss and accuracy ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vw218uDmqhtx"
      },
      "outputs": [],
      "source": [
        "model_data = {\n",
        "    'model_names' : model_names,\n",
        "    'first_layer_nodes' : first_layer_nodes,\n",
        "    'first_layer_activation' : first_layer_activation,\n",
        "    'second_layer_nodes' : second_layer_nodes,\n",
        "    'second_layer_activation' : second_layer_activation,\n",
        "    'output_layer_activation' : output_layer_activation,\n",
        "    'optimizer_function' : optimizer_function,\n",
        "    'loss_function' : loss_function,\n",
        "    'batch_size' : batch_size,\n",
        "    'num_of_epochs' : num_of_epochs,\n",
        "    'training_loss' : training_loss,\n",
        "    'training_accuracy' : training_accuracy,\n",
        "    'validation_loss' : validation_loss,\n",
        "    'validation_accuracy' : validation_accuracy,\n",
        "    'test_loss' : test_loss,\n",
        "    'test_accuracy' : test_accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eYzgm1Lq1yq"
      },
      "source": [
        "**Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O78b_Gw-qv_c"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data = model_data)\n",
        "df = df.set_index('model_names')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OYj2TQ6Yqxdu"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data = model_data)\n",
        "df = df.set_index('model_names')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Highlighter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ouu4UjVYqyic",
        "outputId": "54217644-e5e9-402b-9e90-2ec2ae2e49cc"
      },
      "outputs": [],
      "source": [
        "# max_test_acc = max(df.test_accuracy)\n",
        "\n",
        "# def highlighter(cell_value):\n",
        "    \n",
        "#     highlight = 'background-color: green'\n",
        "#     default = ''\n",
        "\n",
        "#     if cell_value == max_test_acc:\n",
        "#         return highlight\n",
        "#     else:\n",
        "#         return default\n",
        "    \n",
        "# df.style.applymap(highlighter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_layer_nodes</th>\n",
              "      <th>first_layer_activation</th>\n",
              "      <th>second_layer_nodes</th>\n",
              "      <th>second_layer_activation</th>\n",
              "      <th>output_layer_activation</th>\n",
              "      <th>optimizer_function</th>\n",
              "      <th>loss_function</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>num_of_epochs</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>training_accuracy</th>\n",
              "      <th>validation_loss</th>\n",
              "      <th>validation_accuracy</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NN_Model1</th>\n",
              "      <td>150</td>\n",
              "      <td>relu</td>\n",
              "      <td>30</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>0.844024</td>\n",
              "      <td>0.020041</td>\n",
              "      <td>0.843317</td>\n",
              "      <td>0.161303</td>\n",
              "      <td>0.79203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model2</th>\n",
              "      <td>150</td>\n",
              "      <td>relu</td>\n",
              "      <td>50</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.005589</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.019817</td>\n",
              "      <td>0.907917</td>\n",
              "      <td>0.294409</td>\n",
              "      <td>0.88246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model3</th>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>30</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>0.895976</td>\n",
              "      <td>0.019144</td>\n",
              "      <td>0.894550</td>\n",
              "      <td>0.233624</td>\n",
              "      <td>0.84154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model4</th>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>50</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.005038</td>\n",
              "      <td>0.874976</td>\n",
              "      <td>0.019717</td>\n",
              "      <td>0.887217</td>\n",
              "      <td>0.199144</td>\n",
              "      <td>0.81215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model5</th>\n",
              "      <td>150</td>\n",
              "      <td>gelu</td>\n",
              "      <td>30</td>\n",
              "      <td>gelu</td>\n",
              "      <td>softmax</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.gradient_descen...</td>\n",
              "      <td>&lt;keras.losses.Hinge object at 0x000001B5CFE3B040&gt;</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.930914</td>\n",
              "      <td>0.007298</td>\n",
              "      <td>0.928722</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>0.930256</td>\n",
              "      <td>0.00765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model6</th>\n",
              "      <td>150</td>\n",
              "      <td>gelu</td>\n",
              "      <td>50</td>\n",
              "      <td>gelu</td>\n",
              "      <td>softmax</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.005358</td>\n",
              "      <td>0.957972</td>\n",
              "      <td>0.018716</td>\n",
              "      <td>0.952767</td>\n",
              "      <td>0.188839</td>\n",
              "      <td>0.89785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model7</th>\n",
              "      <td>200</td>\n",
              "      <td>gelu</td>\n",
              "      <td>30</td>\n",
              "      <td>gelu</td>\n",
              "      <td>softmax</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.gradient_descen...</td>\n",
              "      <td>&lt;keras.losses.Hinge object at 0x000001B58E8164C0&gt;</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.934836</td>\n",
              "      <td>0.004870</td>\n",
              "      <td>0.931974</td>\n",
              "      <td>0.004450</td>\n",
              "      <td>0.933712</td>\n",
              "      <td>0.00242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model8</th>\n",
              "      <td>200</td>\n",
              "      <td>gelu</td>\n",
              "      <td>50</td>\n",
              "      <td>gelu</td>\n",
              "      <td>softmax</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.BinaryCrossentropy object at 0x0...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>0.005741</td>\n",
              "      <td>0.966204</td>\n",
              "      <td>0.019082</td>\n",
              "      <td>0.954933</td>\n",
              "      <td>0.240633</td>\n",
              "      <td>0.94574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model9</th>\n",
              "      <td>150</td>\n",
              "      <td>elu</td>\n",
              "      <td>30</td>\n",
              "      <td>elu</td>\n",
              "      <td>swish</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.SquaredHinge object at 0x000001B...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.861074</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.861717</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.86318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model10</th>\n",
              "      <td>150</td>\n",
              "      <td>elu</td>\n",
              "      <td>50</td>\n",
              "      <td>elu</td>\n",
              "      <td>swish</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.rmsprop.RMSprop...</td>\n",
              "      <td>&lt;keras.losses.Hinge object at 0x000001B5B0FFECD0&gt;</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873322</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871933</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.87356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model11</th>\n",
              "      <td>200</td>\n",
              "      <td>elu</td>\n",
              "      <td>30</td>\n",
              "      <td>elu</td>\n",
              "      <td>swish</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
              "      <td>&lt;keras.losses.SquaredHinge object at 0x000001B...</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.90000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN_Model12</th>\n",
              "      <td>200</td>\n",
              "      <td>elu</td>\n",
              "      <td>50</td>\n",
              "      <td>elu</td>\n",
              "      <td>swish</td>\n",
              "      <td>&lt;keras.optimizers.optimizer_v2.rmsprop.RMSprop...</td>\n",
              "      <td>&lt;keras.losses.Hinge object at 0x000001B7690F6F70&gt;</td>\n",
              "      <td>250</td>\n",
              "      <td>200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.843420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.84777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             first_layer_nodes first_layer_activation  second_layer_nodes  \\\n",
              "model_names                                                                 \n",
              "NN_Model1                  150                   relu                  30   \n",
              "NN_Model2                  150                   relu                  50   \n",
              "NN_Model3                  200                   relu                  30   \n",
              "NN_Model4                  200                   relu                  50   \n",
              "NN_Model5                  150                   gelu                  30   \n",
              "NN_Model6                  150                   gelu                  50   \n",
              "NN_Model7                  200                   gelu                  30   \n",
              "NN_Model8                  200                   gelu                  50   \n",
              "NN_Model9                  150                    elu                  30   \n",
              "NN_Model10                 150                    elu                  50   \n",
              "NN_Model11                 200                    elu                  30   \n",
              "NN_Model12                 200                    elu                  50   \n",
              "\n",
              "            second_layer_activation output_layer_activation  \\\n",
              "model_names                                                   \n",
              "NN_Model1                      relu                 sigmoid   \n",
              "NN_Model2                      relu                 sigmoid   \n",
              "NN_Model3                      relu                 sigmoid   \n",
              "NN_Model4                      relu                 sigmoid   \n",
              "NN_Model5                      gelu                 softmax   \n",
              "NN_Model6                      gelu                 softmax   \n",
              "NN_Model7                      gelu                 softmax   \n",
              "NN_Model8                      gelu                 softmax   \n",
              "NN_Model9                       elu                   swish   \n",
              "NN_Model10                      elu                   swish   \n",
              "NN_Model11                      elu                   swish   \n",
              "NN_Model12                      elu                   swish   \n",
              "\n",
              "                                            optimizer_function  \\\n",
              "model_names                                                      \n",
              "NN_Model1    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model2    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model3    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model4    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model5    <keras.optimizers.optimizer_v2.gradient_descen...   \n",
              "NN_Model6    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model7    <keras.optimizers.optimizer_v2.gradient_descen...   \n",
              "NN_Model8    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model9    <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model10   <keras.optimizers.optimizer_v2.rmsprop.RMSprop...   \n",
              "NN_Model11   <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
              "NN_Model12   <keras.optimizers.optimizer_v2.rmsprop.RMSprop...   \n",
              "\n",
              "                                                 loss_function  batch_size  \\\n",
              "model_names                                                                  \n",
              "NN_Model1    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model2    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model3    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model4    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model5    <keras.losses.Hinge object at 0x000001B5CFE3B040>         250   \n",
              "NN_Model6    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model7    <keras.losses.Hinge object at 0x000001B58E8164C0>         250   \n",
              "NN_Model8    <keras.losses.BinaryCrossentropy object at 0x0...         250   \n",
              "NN_Model9    <keras.losses.SquaredHinge object at 0x000001B...         250   \n",
              "NN_Model10   <keras.losses.Hinge object at 0x000001B5B0FFECD0>         250   \n",
              "NN_Model11   <keras.losses.SquaredHinge object at 0x000001B...         250   \n",
              "NN_Model12   <keras.losses.Hinge object at 0x000001B7690F6F70>         250   \n",
              "\n",
              "             num_of_epochs  training_loss  training_accuracy  validation_loss  \\\n",
              "model_names                                                                     \n",
              "NN_Model1              200       0.003301           0.844024         0.020041   \n",
              "NN_Model2              200       0.005589           0.898400         0.019817   \n",
              "NN_Model3              200       0.005373           0.895976         0.019144   \n",
              "NN_Model4              200       0.005038           0.874976         0.019717   \n",
              "NN_Model5              200       0.930914           0.007298         0.928722   \n",
              "NN_Model6              200       0.005358           0.957972         0.018716   \n",
              "NN_Model7              200       0.934836           0.004870         0.931974   \n",
              "NN_Model8              200       0.005741           0.966204         0.019082   \n",
              "NN_Model9              200       1.000000           0.861074         0.999998   \n",
              "NN_Model10             200       1.000000           0.873322         1.000000   \n",
              "NN_Model11             200       1.000000           0.900000         1.000000   \n",
              "NN_Model12             200       1.000000           0.843420         1.000000   \n",
              "\n",
              "             validation_accuracy  test_loss  test_accuracy  \n",
              "model_names                                                 \n",
              "NN_Model1               0.843317   0.161303        0.79203  \n",
              "NN_Model2               0.907917   0.294409        0.88246  \n",
              "NN_Model3               0.894550   0.233624        0.84154  \n",
              "NN_Model4               0.887217   0.199144        0.81215  \n",
              "NN_Model5               0.007217   0.930256        0.00765  \n",
              "NN_Model6               0.952767   0.188839        0.89785  \n",
              "NN_Model7               0.004450   0.933712        0.00242  \n",
              "NN_Model8               0.954933   0.240633        0.94574  \n",
              "NN_Model9               0.861717   1.000000        0.86318  \n",
              "NN_Model10              0.871933   1.000000        0.87356  \n",
              "NN_Model11              0.900000   1.000000        0.90000  \n",
              "NN_Model12              0.846667   1.000000        0.84777  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
