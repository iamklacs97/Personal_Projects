{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages and libraries"
      ],
      "metadata": {
        "id": "eXfvihT3DzSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility packages\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# tensorflow \n",
        "import tensorflow as tf\n",
        "\n",
        "# random package\n",
        "import random \n",
        "\n",
        "# warnings \n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Dp3iL5aUECDL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for GPU usage"
      ],
      "metadata": {
        "id": "_ZON9yN0ESBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':  \n",
        "  print(f'No GPU was found.')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pQjQfwOE7CJ",
        "outputId": "f832bbe7-e573-4724-bae8-efdc762a99c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU was found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "64hMBWIjE7fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "g697hdknFCMm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### unzipping the mnist dataset \n",
        "\n",
        "(xTrain,yTrainLabel),(xTest,yTestLabel) = mnist.load_data()"
      ],
      "metadata": {
        "id": "42QBUpOaFGZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63a1d3b-d66e-42c3-faea-980dcb75004c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulation the MNIST dataset"
      ],
      "metadata": {
        "id": "H5vSZwC8KC6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### One-hot encoding the training and test labels\n",
        "\n",
        "classes = 10 # 0-9 categories for the num_classes parameter\n",
        "\n",
        "# training\n",
        "yTrainCat = tf.keras.utils.to_categorical(y = yTrainLabel, num_classes = classes, dtype = 'float32')\n",
        "\n",
        "# testing\n",
        "yTestCat = tf.keras.utils.to_categorical(y = yTestLabel, num_classes = classes, dtype = 'float32')"
      ],
      "metadata": {
        "id": "BFNNt2RtFQrt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Shape and datatype of MNIST dataset\n",
        "\n",
        "print(f'Training dataset shape: {xTrain.shape} | Training dataset datatype: {xTrain.dtype} \\nTesting dataset shape: {xTest.shape} | Testing dataset datatype: {xTrain.dtype}')\n",
        "print(f'Training dataset pixel range: {(np.min(xTrain),np.max(xTrain))} | Testing dataset pixel range: {(np.min(xTest),np.max(xTest))}' )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRZlRICcGTRY",
        "outputId": "11c26d3d-67d6-43f3-e36f-6a966de9c827"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: (60000, 28, 28) | Training dataset datatype: uint8 \n",
            "Testing dataset shape: (10000, 28, 28) | Testing dataset datatype: uint8\n",
            "Training dataset pixel range: (0, 255) | Testing dataset pixel range: (0, 255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Need to reshape, change the datatype, and min_max scale the tensor values**"
      ],
      "metadata": {
        "id": "5HbyMhI6JtzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Manipulate the training and testing input\n",
        "\n",
        "xTrain = (xTrain/255).astype('float32') # 0-1 scaled, datatype is now a float\n",
        "xTest = (xTest/255).astype('float32') # 0-1 scaled, datatype is now a float"
      ],
      "metadata": {
        "id": "OC_g8N5OK0Ao"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build and establish the model\n",
        "The upper restriciton on the number of params: 200,000. I will initialize a function api model using keras.\n"
      ],
      "metadata": {
        "id": "9Kd4V3LGLuHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Model ### --- layer adjustments\n",
        "\n",
        "#creating lists for column names \n",
        "model_names = []\n",
        "first_layer_nodes = []\n",
        "second_layer_nodes = []\n",
        "first_layer_activation = []\n",
        "second_layer_activation = []\n",
        "output_layer_activation = []\n",
        "training_loss = []\n",
        "training_accuracy = []\n",
        "validation_loss = []\n",
        "validation_accuracy = []\n",
        "batch_size = [] \n",
        "num_of_epochs = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "optimizer_function = []\n",
        "loss_function = []\n",
        "\n",
        "def model_builder(training_dataset = xTrain, \n",
        "                  training_labels = yTrainCat, \n",
        "                  testing_dataset = xTest, \n",
        "                  testing_labels = yTestCat):\n",
        "  \n",
        "  ### ----- Local Variables ----- ###\n",
        "  counter = 0\n",
        "  firstActive = 'relu'\n",
        "  secondActive = 'relu'\n",
        "  outputActive = 'sigmoid'\n",
        "  firstLayerNodes = [100,150,200] # number of nodes in first layer list\n",
        "  secondLayerNodes = [50,87,125]  # number of nodes in second layer list\n",
        "\n",
        "  ### ----- Creating the full-dense network ----- ###\n",
        "\n",
        "  for i in firstLayerNodes: # will iterate through first layer nodes\n",
        "    for j in secondLayerNodes: # iterate through second layer nodes\n",
        "      counter += 1\n",
        "      inputLayer = tf.keras.Input(shape = (28,28), name = 'input_layer')\n",
        "      flattenLayer = tf.keras.layers.Flatten(name = 'flatten_layer')(inputLayer)\n",
        "      denseLayer1 = tf.keras.layers.Dense(units = i, activation = firstActive, name = 'dense_layer_1')(flattenLayer)\n",
        "      denseLayer2 = tf.keras.layers.Dense(units = j, activation = secondActive, name = 'dense_layer_2')(denseLayer1)\n",
        "      outputLayer = tf.keras.layers.Dense(units = 10, activation = outputActive, name = 'output_layer')(denseLayer2)\n",
        "\n",
        "      # appending all hyperparameters into lists\n",
        "      first_layer_nodes.append(i) # append number of first layer nodes \n",
        "      second_layer_nodes.append(j) # append number of second layer nodes\n",
        "      first_layer_activation.append(firstActive) # append first layer activation function\n",
        "      second_layer_activation.append(secondActive) # append second layer activation function\n",
        "      output_layer_activation.append(outputActive) # append output layer activation function\n",
        "\n",
        "      modelName = f'NN_Model{str(counter)}' # generating model names to put into list\n",
        "      model_names.append(modelName) # appending name to model_names list\n",
        "\n",
        "      model = tf.keras.Model(inputs = inputLayer, outputs = outputLayer, name = modelName)\n",
        "\n",
        "      ### ----- Model Parameters ----- ###\n",
        "\n",
        "      optFunction = tf.keras.optimizers.Adam(learning_rate =  0.025) # optimizer function\n",
        "      lossFunction = tf.keras.losses.BinaryCrossentropy() # loss function\n",
        "\n",
        "      optimizer_function.append(str(optFunction)) # append optimizer function\n",
        "      loss_function.append(str(lossFunction)) # append loss function\n",
        "\n",
        "      ### ----- Compiler ----- ###\n",
        "      model.compile(\n",
        "        optimizer = optFunction,\n",
        "        loss = lossFunction,\n",
        "        metrics = tf.keras.metrics.Accuracy()\n",
        "      )\n",
        "\n",
        "      ##### ----- Fitting the model ----- ###\n",
        "      print(f'first layer: {i}, second layer {j}') \n",
        "\n",
        "      tf.random.set_seed(42)\n",
        "\n",
        "      bSize = 200\n",
        "      epoch = 250 \n",
        "      vSplit = 0.1\n",
        "      trainModel = model.fit(\n",
        "          x = xTrain,\n",
        "          y = yTrainCat,\n",
        "          batch_size = bSize,\n",
        "          epochs = epoch,\n",
        "          validation_split = vSplit\n",
        "      )\n",
        "\n",
        "      batch_size.append(bSize) # append batch size\n",
        "      num_of_epochs.append(epoch) # append number of epochs \n",
        "      \n",
        "      ### ----- Results ----- ###\n",
        "      # appending the validation accuracy into the list\n",
        "      training_loss.append(min(trainModel.history['loss'])) # append training loss\n",
        "      training_accuracy.append(max(trainModel.history['accuracy'])) # append training accuracy\n",
        "      validation_loss.append(min(trainModel.history['val_loss'])) # append validation loss\n",
        "      validation_accuracy.append(max(trainModel.history['val_accuracy'])) # append validation accuracy \n",
        "                                 \n",
        "      # appending the test accuracy into the list\n",
        "      finalResults = model.evaluate(xTest,yTestCat)\n",
        "\n",
        "      test_loss.append(finalResults[0]) # append test loss\n",
        "      test_accuracy.append(finalResults[1]) # append test accuracy"
      ],
      "metadata": {
        "id": "4trvpgZYMM0b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the hyper-parameter tunned Model ### \n",
        "This first round of models controls the number of nodes/perceptrons within the model."
      ],
      "metadata": {
        "id": "87ukMxm5qPTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_builder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84UX7eL7qOdx",
        "outputId": "d2950b37-228d-4729-ed8a-77909cedefd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first layer: 100, second layer 50\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 5s 11ms/step - loss: 0.0802 - accuracy: 5.1852e-05 - val_loss: 0.0297 - val_accuracy: 7.6667e-04\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 4s 13ms/step - loss: 0.0337 - accuracy: 4.7222e-04 - val_loss: 0.0273 - val_accuracy: 3.8333e-04\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0273 - accuracy: 8.8148e-04 - val_loss: 0.0249 - val_accuracy: 0.0041\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0244 - accuracy: 0.0018 - val_loss: 0.0233 - val_accuracy: 8.1667e-04\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0215 - accuracy: 0.0037 - val_loss: 0.0236 - val_accuracy: 0.0058\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0203 - accuracy: 0.0063 - val_loss: 0.0250 - val_accuracy: 0.0036\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 4s 14ms/step - loss: 0.0189 - accuracy: 0.0087 - val_loss: 0.0257 - val_accuracy: 0.0133\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0177 - accuracy: 0.0124 - val_loss: 0.0253 - val_accuracy: 0.0083\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0175 - accuracy: 0.0133 - val_loss: 0.0256 - val_accuracy: 0.0145\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.0163 - val_loss: 0.0242 - val_accuracy: 0.0187\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.0174\n",
            "first layer: 100, second layer 87\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0646 - accuracy: 7.2222e-05 - val_loss: 0.0273 - val_accuracy: 1.3333e-04\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 5.2222e-04 - val_loss: 0.0242 - val_accuracy: 0.0017\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0248 - accuracy: 0.0023 - val_loss: 0.0221 - val_accuracy: 0.0025\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0230 - accuracy: 0.0045 - val_loss: 0.0240 - val_accuracy: 0.0054\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.0067 - val_loss: 0.0223 - val_accuracy: 0.0111\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.0127 - val_loss: 0.0249 - val_accuracy: 0.0075\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0182 - accuracy: 0.0134 - val_loss: 0.0232 - val_accuracy: 0.0114\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0174 - accuracy: 0.0197 - val_loss: 0.0241 - val_accuracy: 0.0246\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.0239 - val_loss: 0.0237 - val_accuracy: 0.0385\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.0171 - accuracy: 0.0302 - val_loss: 0.0248 - val_accuracy: 0.0344\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.0324\n",
            "first layer: 100, second layer 125\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0695 - accuracy: 2.5926e-05 - val_loss: 0.0301 - val_accuracy: 3.3333e-05\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 4.9074e-04 - val_loss: 0.0267 - val_accuracy: 0.0016\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0280 - accuracy: 0.0018 - val_loss: 0.0241 - val_accuracy: 0.0016\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0258 - accuracy: 0.0040 - val_loss: 0.0243 - val_accuracy: 0.0043\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0248 - accuracy: 0.0073 - val_loss: 0.0272 - val_accuracy: 0.0111\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.0104 - val_loss: 0.0283 - val_accuracy: 0.0119\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0221 - accuracy: 0.0150 - val_loss: 0.0234 - val_accuracy: 0.0092\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.0192 - val_loss: 0.0286 - val_accuracy: 0.0202\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.0199 - val_loss: 0.0305 - val_accuracy: 0.0273\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 0.0196 - accuracy: 0.0261 - val_loss: 0.0307 - val_accuracy: 0.0347\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.0325\n",
            "first layer: 150, second layer 50\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 3s 8ms/step - loss: 0.0647 - accuracy: 7.2222e-05 - val_loss: 0.0250 - val_accuracy: 1.5000e-04\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0279 - accuracy: 4.3519e-04 - val_loss: 0.0223 - val_accuracy: 8.3333e-04\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.0021 - val_loss: 0.0233 - val_accuracy: 0.0026\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0198 - accuracy: 0.0045 - val_loss: 0.0171 - val_accuracy: 0.0033\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0187 - accuracy: 0.0075 - val_loss: 0.0203 - val_accuracy: 0.0060\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0168 - accuracy: 0.0091 - val_loss: 0.0199 - val_accuracy: 0.0094\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0159 - accuracy: 0.0148 - val_loss: 0.0236 - val_accuracy: 0.0170\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 3s 9ms/step - loss: 0.0154 - accuracy: 0.0179 - val_loss: 0.0204 - val_accuracy: 0.0216\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0144 - accuracy: 0.0216 - val_loss: 0.0224 - val_accuracy: 0.0275\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0146 - accuracy: 0.0265 - val_loss: 0.0235 - val_accuracy: 0.0327\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.0302\n",
            "first layer: 150, second layer 87\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 3s 9ms/step - loss: 0.0631 - accuracy: 1.0000e-04 - val_loss: 0.0262 - val_accuracy: 2.0000e-04\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0294 - accuracy: 5.7407e-04 - val_loss: 0.0209 - val_accuracy: 0.0039\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0235 - accuracy: 0.0019 - val_loss: 0.0196 - val_accuracy: 0.0015\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0210 - accuracy: 0.0029 - val_loss: 0.0275 - val_accuracy: 0.0046\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0201 - accuracy: 0.0069 - val_loss: 0.0212 - val_accuracy: 0.0060\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0184 - accuracy: 0.0114 - val_loss: 0.0213 - val_accuracy: 0.0053\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0177 - accuracy: 0.0165 - val_loss: 0.0223 - val_accuracy: 0.0365\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0175 - accuracy: 0.0253 - val_loss: 0.0238 - val_accuracy: 0.0281\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0161 - accuracy: 0.0306 - val_loss: 0.0213 - val_accuracy: 0.0300\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0152 - accuracy: 0.0363 - val_loss: 0.0279 - val_accuracy: 0.0454\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.0426\n",
            "first layer: 150, second layer 125\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 3s 8ms/step - loss: 0.0675 - accuracy: 8.5185e-05 - val_loss: 0.0255 - val_accuracy: 0.0021\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0276 - accuracy: 9.2778e-04 - val_loss: 0.0223 - val_accuracy: 4.8333e-04\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0222 - accuracy: 0.0030 - val_loss: 0.0225 - val_accuracy: 0.0037\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0197 - accuracy: 0.0064 - val_loss: 0.0205 - val_accuracy: 0.0064\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0190 - accuracy: 0.0096 - val_loss: 0.0250 - val_accuracy: 0.0135\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0182 - accuracy: 0.0157 - val_loss: 0.0245 - val_accuracy: 0.0181\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0170 - accuracy: 0.0227 - val_loss: 0.0241 - val_accuracy: 0.0287\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0166 - accuracy: 0.0287 - val_loss: 0.0244 - val_accuracy: 0.0264\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0171 - accuracy: 0.0331 - val_loss: 0.0248 - val_accuracy: 0.0421\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0168 - accuracy: 0.0400 - val_loss: 0.0211 - val_accuracy: 0.0481\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.0433\n",
            "first layer: 200, second layer 50\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 4s 11ms/step - loss: 0.0732 - accuracy: 4.0185e-04 - val_loss: 0.0280 - val_accuracy: 0.0014\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0288 - accuracy: 0.0010 - val_loss: 0.0233 - val_accuracy: 0.0016\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0231 - accuracy: 0.0017 - val_loss: 0.0217 - val_accuracy: 0.0025\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0199 - accuracy: 0.0023 - val_loss: 0.0196 - val_accuracy: 6.5000e-04\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0180 - accuracy: 0.0036 - val_loss: 0.0213 - val_accuracy: 0.0072\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0166 - accuracy: 0.0086 - val_loss: 0.0221 - val_accuracy: 0.0046\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0151 - accuracy: 0.0101 - val_loss: 0.0223 - val_accuracy: 0.0102\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0140 - accuracy: 0.0111 - val_loss: 0.0212 - val_accuracy: 0.0148\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0147 - accuracy: 0.0141 - val_loss: 0.0253 - val_accuracy: 0.0207\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0137 - accuracy: 0.0211 - val_loss: 0.0225 - val_accuracy: 0.0193\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.0171\n",
            "first layer: 200, second layer 87\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 3s 8ms/step - loss: 0.0649 - accuracy: 4.7407e-04 - val_loss: 0.0254 - val_accuracy: 6.5000e-04\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0277 - accuracy: 0.0017 - val_loss: 0.0208 - val_accuracy: 0.0019\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0218 - accuracy: 0.0034 - val_loss: 0.0199 - val_accuracy: 0.0049\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0194 - accuracy: 0.0082 - val_loss: 0.0207 - val_accuracy: 0.0086\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0166 - accuracy: 0.0143 - val_loss: 0.0213 - val_accuracy: 0.0178\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0163 - accuracy: 0.0170 - val_loss: 0.0211 - val_accuracy: 0.0205\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0157 - accuracy: 0.0228 - val_loss: 0.0196 - val_accuracy: 0.0225\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 0.0148 - accuracy: 0.0280 - val_loss: 0.0207 - val_accuracy: 0.0353\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0143 - accuracy: 0.0336 - val_loss: 0.0247 - val_accuracy: 0.0336\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 3s 9ms/step - loss: 0.0143 - accuracy: 0.0403 - val_loss: 0.0244 - val_accuracy: 0.0528\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.0507\n",
            "first layer: 200, second layer 125\n",
            "Epoch 1/10\n",
            "270/270 [==============================] - 3s 9ms/step - loss: 0.0643 - accuracy: 7.5926e-05 - val_loss: 0.0281 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0277 - accuracy: 3.7593e-04 - val_loss: 0.0225 - val_accuracy: 0.0013\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0232 - accuracy: 0.0019 - val_loss: 0.0218 - val_accuracy: 0.0018\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0208 - accuracy: 0.0040 - val_loss: 0.0211 - val_accuracy: 0.0039\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 3s 10ms/step - loss: 0.0196 - accuracy: 0.0079 - val_loss: 0.0218 - val_accuracy: 0.0082\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 0.0185 - accuracy: 0.0144 - val_loss: 0.0256 - val_accuracy: 0.0136\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0172 - accuracy: 0.0181 - val_loss: 0.0234 - val_accuracy: 0.0209\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0169 - accuracy: 0.0233 - val_loss: 0.0296 - val_accuracy: 0.0260\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 0.0164 - accuracy: 0.0269 - val_loss: 0.0249 - val_accuracy: 0.0317\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 3s 12ms/step - loss: 0.0158 - accuracy: 0.0365 - val_loss: 0.0214 - val_accuracy: 0.0388\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.0370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the dataframe that denotes all hyperparameters and their respective loss and accuracy ###"
      ],
      "metadata": {
        "id": "HisIR0-mqim-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = {\n",
        "    'model_names' : model_names,\n",
        "    'first_layer_nodes' : first_layer_nodes,\n",
        "    'first_layer_activation' : first_layer_activation,\n",
        "    'second_layer_nodes' : second_layer_nodes,\n",
        "    'second_layer_activation' : second_layer_activation,\n",
        "    'output_layer_activation' : output_layer_activation,\n",
        "    'optimizer_function' : optimizer_function,\n",
        "    'loss_function' : loss_function,\n",
        "    'batch_size' : batch_size,\n",
        "    'num_of_epochs' : num_of_epochs,\n",
        "    'training_loss' : training_loss,\n",
        "    'training_accuracy' : training_accuracy,\n",
        "    'validation_loss' : validation_loss,\n",
        "    'validation_accuracy' : validation_accuracy,\n",
        "    'test_loss' : test_loss,\n",
        "    'test_accuracy' : test_accuracy\n",
        "}"
      ],
      "metadata": {
        "id": "Vw218uDmqhtx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe**"
      ],
      "metadata": {
        "id": "7eYzgm1Lq1yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data = model_data)\n",
        "df = df.set_index('model_names')"
      ],
      "metadata": {
        "id": "O78b_Gw-qv_c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data = model_data)\n",
        "df = df.set_index('model_names')"
      ],
      "metadata": {
        "id": "OYj2TQ6Yqxdu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_test_acc = max(df.test_accuracy)\n",
        "\n",
        "def highlighter(cell_value):\n",
        "    \n",
        "    highlight = 'background-color: green'\n",
        "    default = ''\n",
        "\n",
        "    if cell_value == max_test_acc:\n",
        "        return highlight\n",
        "    else:\n",
        "        return default\n",
        "    \n",
        "df.style.applymap(highlighter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ouu4UjVYqyic",
        "outputId": "54217644-e5e9-402b-9e90-2ec2ae2e49cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f2deec69e80>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b44a5_row7_col14 {\n",
              "  background-color: green;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b44a5\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b44a5_level0_col0\" class=\"col_heading level0 col0\" >first_layer_nodes</th>\n",
              "      <th id=\"T_b44a5_level0_col1\" class=\"col_heading level0 col1\" >first_layer_activation</th>\n",
              "      <th id=\"T_b44a5_level0_col2\" class=\"col_heading level0 col2\" >second_layer_nodes</th>\n",
              "      <th id=\"T_b44a5_level0_col3\" class=\"col_heading level0 col3\" >second_layer_activation</th>\n",
              "      <th id=\"T_b44a5_level0_col4\" class=\"col_heading level0 col4\" >output_layer_activation</th>\n",
              "      <th id=\"T_b44a5_level0_col5\" class=\"col_heading level0 col5\" >optimizer_function</th>\n",
              "      <th id=\"T_b44a5_level0_col6\" class=\"col_heading level0 col6\" >loss_function</th>\n",
              "      <th id=\"T_b44a5_level0_col7\" class=\"col_heading level0 col7\" >batch_size</th>\n",
              "      <th id=\"T_b44a5_level0_col8\" class=\"col_heading level0 col8\" >num_of_epochs</th>\n",
              "      <th id=\"T_b44a5_level0_col9\" class=\"col_heading level0 col9\" >training_loss</th>\n",
              "      <th id=\"T_b44a5_level0_col10\" class=\"col_heading level0 col10\" >training_accuracy</th>\n",
              "      <th id=\"T_b44a5_level0_col11\" class=\"col_heading level0 col11\" >validation_loss</th>\n",
              "      <th id=\"T_b44a5_level0_col12\" class=\"col_heading level0 col12\" >validation_accuracy</th>\n",
              "      <th id=\"T_b44a5_level0_col13\" class=\"col_heading level0 col13\" >test_loss</th>\n",
              "      <th id=\"T_b44a5_level0_col14\" class=\"col_heading level0 col14\" >test_accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >model_names</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "      <th class=\"blank col5\" >&nbsp;</th>\n",
              "      <th class=\"blank col6\" >&nbsp;</th>\n",
              "      <th class=\"blank col7\" >&nbsp;</th>\n",
              "      <th class=\"blank col8\" >&nbsp;</th>\n",
              "      <th class=\"blank col9\" >&nbsp;</th>\n",
              "      <th class=\"blank col10\" >&nbsp;</th>\n",
              "      <th class=\"blank col11\" >&nbsp;</th>\n",
              "      <th class=\"blank col12\" >&nbsp;</th>\n",
              "      <th class=\"blank col13\" >&nbsp;</th>\n",
              "      <th class=\"blank col14\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row0\" class=\"row_heading level0 row0\" >NN_Model1</th>\n",
              "      <td id=\"T_b44a5_row0_col0\" class=\"data row0 col0\" >100</td>\n",
              "      <td id=\"T_b44a5_row0_col1\" class=\"data row0 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row0_col2\" class=\"data row0 col2\" >50</td>\n",
              "      <td id=\"T_b44a5_row0_col3\" class=\"data row0 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row0_col4\" class=\"data row0 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row0_col5\" class=\"data row0 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2df8476640></td>\n",
              "      <td id=\"T_b44a5_row0_col6\" class=\"data row0 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2df4df2fd0></td>\n",
              "      <td id=\"T_b44a5_row0_col7\" class=\"data row0 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row0_col8\" class=\"data row0 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row0_col9\" class=\"data row0 col9\" >0.016792</td>\n",
              "      <td id=\"T_b44a5_row0_col10\" class=\"data row0 col10\" >0.016317</td>\n",
              "      <td id=\"T_b44a5_row0_col11\" class=\"data row0 col11\" >0.023322</td>\n",
              "      <td id=\"T_b44a5_row0_col12\" class=\"data row0 col12\" >0.018667</td>\n",
              "      <td id=\"T_b44a5_row0_col13\" class=\"data row0 col13\" >0.025328</td>\n",
              "      <td id=\"T_b44a5_row0_col14\" class=\"data row0 col14\" >0.017390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row1\" class=\"row_heading level0 row1\" >NN_Model2</th>\n",
              "      <td id=\"T_b44a5_row1_col0\" class=\"data row1 col0\" >100</td>\n",
              "      <td id=\"T_b44a5_row1_col1\" class=\"data row1 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row1_col2\" class=\"data row1 col2\" >87</td>\n",
              "      <td id=\"T_b44a5_row1_col3\" class=\"data row1 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row1_col4\" class=\"data row1 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row1_col5\" class=\"data row1 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2deb2d1bb0></td>\n",
              "      <td id=\"T_b44a5_row1_col6\" class=\"data row1 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2def7d0f40></td>\n",
              "      <td id=\"T_b44a5_row1_col7\" class=\"data row1 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row1_col8\" class=\"data row1 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row1_col9\" class=\"data row1 col9\" >0.016780</td>\n",
              "      <td id=\"T_b44a5_row1_col10\" class=\"data row1 col10\" >0.030215</td>\n",
              "      <td id=\"T_b44a5_row1_col11\" class=\"data row1 col11\" >0.022101</td>\n",
              "      <td id=\"T_b44a5_row1_col12\" class=\"data row1 col12\" >0.038467</td>\n",
              "      <td id=\"T_b44a5_row1_col13\" class=\"data row1 col13\" >0.027440</td>\n",
              "      <td id=\"T_b44a5_row1_col14\" class=\"data row1 col14\" >0.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row2\" class=\"row_heading level0 row2\" >NN_Model3</th>\n",
              "      <td id=\"T_b44a5_row2_col0\" class=\"data row2 col0\" >100</td>\n",
              "      <td id=\"T_b44a5_row2_col1\" class=\"data row2 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row2_col2\" class=\"data row2 col2\" >125</td>\n",
              "      <td id=\"T_b44a5_row2_col3\" class=\"data row2 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row2_col4\" class=\"data row2 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row2_col5\" class=\"data row2 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2deee6c100></td>\n",
              "      <td id=\"T_b44a5_row2_col6\" class=\"data row2 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2deee28a90></td>\n",
              "      <td id=\"T_b44a5_row2_col7\" class=\"data row2 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row2_col8\" class=\"data row2 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row2_col9\" class=\"data row2 col9\" >0.019608</td>\n",
              "      <td id=\"T_b44a5_row2_col10\" class=\"data row2 col10\" >0.026096</td>\n",
              "      <td id=\"T_b44a5_row2_col11\" class=\"data row2 col11\" >0.023407</td>\n",
              "      <td id=\"T_b44a5_row2_col12\" class=\"data row2 col12\" >0.034733</td>\n",
              "      <td id=\"T_b44a5_row2_col13\" class=\"data row2 col13\" >0.032271</td>\n",
              "      <td id=\"T_b44a5_row2_col14\" class=\"data row2 col14\" >0.032450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row3\" class=\"row_heading level0 row3\" >NN_Model4</th>\n",
              "      <td id=\"T_b44a5_row3_col0\" class=\"data row3 col0\" >150</td>\n",
              "      <td id=\"T_b44a5_row3_col1\" class=\"data row3 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row3_col2\" class=\"data row3 col2\" >50</td>\n",
              "      <td id=\"T_b44a5_row3_col3\" class=\"data row3 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row3_col4\" class=\"data row3 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row3_col5\" class=\"data row3 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2def5b2910></td>\n",
              "      <td id=\"T_b44a5_row3_col6\" class=\"data row3 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2def533580></td>\n",
              "      <td id=\"T_b44a5_row3_col7\" class=\"data row3 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row3_col8\" class=\"data row3 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row3_col9\" class=\"data row3 col9\" >0.014361</td>\n",
              "      <td id=\"T_b44a5_row3_col10\" class=\"data row3 col10\" >0.026535</td>\n",
              "      <td id=\"T_b44a5_row3_col11\" class=\"data row3 col11\" >0.017129</td>\n",
              "      <td id=\"T_b44a5_row3_col12\" class=\"data row3 col12\" >0.032650</td>\n",
              "      <td id=\"T_b44a5_row3_col13\" class=\"data row3 col13\" >0.026774</td>\n",
              "      <td id=\"T_b44a5_row3_col14\" class=\"data row3 col14\" >0.030240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row4\" class=\"row_heading level0 row4\" >NN_Model5</th>\n",
              "      <td id=\"T_b44a5_row4_col0\" class=\"data row4 col0\" >150</td>\n",
              "      <td id=\"T_b44a5_row4_col1\" class=\"data row4 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row4_col2\" class=\"data row4 col2\" >87</td>\n",
              "      <td id=\"T_b44a5_row4_col3\" class=\"data row4 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row4_col4\" class=\"data row4 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row4_col5\" class=\"data row4 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2def5ba460></td>\n",
              "      <td id=\"T_b44a5_row4_col6\" class=\"data row4 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2def37be50></td>\n",
              "      <td id=\"T_b44a5_row4_col7\" class=\"data row4 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row4_col8\" class=\"data row4 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row4_col9\" class=\"data row4 col9\" >0.015180</td>\n",
              "      <td id=\"T_b44a5_row4_col10\" class=\"data row4 col10\" >0.036254</td>\n",
              "      <td id=\"T_b44a5_row4_col11\" class=\"data row4 col11\" >0.019605</td>\n",
              "      <td id=\"T_b44a5_row4_col12\" class=\"data row4 col12\" >0.045400</td>\n",
              "      <td id=\"T_b44a5_row4_col13\" class=\"data row4 col13\" >0.029222</td>\n",
              "      <td id=\"T_b44a5_row4_col14\" class=\"data row4 col14\" >0.042570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row5\" class=\"row_heading level0 row5\" >NN_Model6</th>\n",
              "      <td id=\"T_b44a5_row5_col0\" class=\"data row5 col0\" >150</td>\n",
              "      <td id=\"T_b44a5_row5_col1\" class=\"data row5 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row5_col2\" class=\"data row5 col2\" >125</td>\n",
              "      <td id=\"T_b44a5_row5_col3\" class=\"data row5 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row5_col4\" class=\"data row5 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row5_col5\" class=\"data row5 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2def141a00></td>\n",
              "      <td id=\"T_b44a5_row5_col6\" class=\"data row5 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2def174a30></td>\n",
              "      <td id=\"T_b44a5_row5_col7\" class=\"data row5 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row5_col8\" class=\"data row5 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row5_col9\" class=\"data row5 col9\" >0.016644</td>\n",
              "      <td id=\"T_b44a5_row5_col10\" class=\"data row5 col10\" >0.039961</td>\n",
              "      <td id=\"T_b44a5_row5_col11\" class=\"data row5 col11\" >0.020471</td>\n",
              "      <td id=\"T_b44a5_row5_col12\" class=\"data row5 col12\" >0.048133</td>\n",
              "      <td id=\"T_b44a5_row5_col13\" class=\"data row5 col13\" >0.027021</td>\n",
              "      <td id=\"T_b44a5_row5_col14\" class=\"data row5 col14\" >0.043350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row6\" class=\"row_heading level0 row6\" >NN_Model7</th>\n",
              "      <td id=\"T_b44a5_row6_col0\" class=\"data row6 col0\" >200</td>\n",
              "      <td id=\"T_b44a5_row6_col1\" class=\"data row6 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row6_col2\" class=\"data row6 col2\" >50</td>\n",
              "      <td id=\"T_b44a5_row6_col3\" class=\"data row6 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row6_col4\" class=\"data row6 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row6_col5\" class=\"data row6 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2deefecd60></td>\n",
              "      <td id=\"T_b44a5_row6_col6\" class=\"data row6 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2deefb16d0></td>\n",
              "      <td id=\"T_b44a5_row6_col7\" class=\"data row6 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row6_col8\" class=\"data row6 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row6_col9\" class=\"data row6 col9\" >0.013724</td>\n",
              "      <td id=\"T_b44a5_row6_col10\" class=\"data row6 col10\" >0.021141</td>\n",
              "      <td id=\"T_b44a5_row6_col11\" class=\"data row6 col11\" >0.019574</td>\n",
              "      <td id=\"T_b44a5_row6_col12\" class=\"data row6 col12\" >0.020717</td>\n",
              "      <td id=\"T_b44a5_row6_col13\" class=\"data row6 col13\" >0.024502</td>\n",
              "      <td id=\"T_b44a5_row6_col14\" class=\"data row6 col14\" >0.017060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row7\" class=\"row_heading level0 row7\" >NN_Model8</th>\n",
              "      <td id=\"T_b44a5_row7_col0\" class=\"data row7 col0\" >200</td>\n",
              "      <td id=\"T_b44a5_row7_col1\" class=\"data row7 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row7_col2\" class=\"data row7 col2\" >87</td>\n",
              "      <td id=\"T_b44a5_row7_col3\" class=\"data row7 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row7_col4\" class=\"data row7 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row7_col5\" class=\"data row7 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2dedd5e580></td>\n",
              "      <td id=\"T_b44a5_row7_col6\" class=\"data row7 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2dedd36a00></td>\n",
              "      <td id=\"T_b44a5_row7_col7\" class=\"data row7 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row7_col8\" class=\"data row7 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row7_col9\" class=\"data row7 col9\" >0.014260</td>\n",
              "      <td id=\"T_b44a5_row7_col10\" class=\"data row7 col10\" >0.040257</td>\n",
              "      <td id=\"T_b44a5_row7_col11\" class=\"data row7 col11\" >0.019621</td>\n",
              "      <td id=\"T_b44a5_row7_col12\" class=\"data row7 col12\" >0.052817</td>\n",
              "      <td id=\"T_b44a5_row7_col13\" class=\"data row7 col13\" >0.029096</td>\n",
              "      <td id=\"T_b44a5_row7_col14\" class=\"data row7 col14\" >0.050650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b44a5_level0_row8\" class=\"row_heading level0 row8\" >NN_Model9</th>\n",
              "      <td id=\"T_b44a5_row8_col0\" class=\"data row8 col0\" >200</td>\n",
              "      <td id=\"T_b44a5_row8_col1\" class=\"data row8 col1\" >relu</td>\n",
              "      <td id=\"T_b44a5_row8_col2\" class=\"data row8 col2\" >125</td>\n",
              "      <td id=\"T_b44a5_row8_col3\" class=\"data row8 col3\" >relu</td>\n",
              "      <td id=\"T_b44a5_row8_col4\" class=\"data row8 col4\" >sigmoid</td>\n",
              "      <td id=\"T_b44a5_row8_col5\" class=\"data row8 col5\" ><keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f2deec0ee20></td>\n",
              "      <td id=\"T_b44a5_row8_col6\" class=\"data row8 col6\" ><keras.losses.BinaryCrossentropy object at 0x7f2deec2e580></td>\n",
              "      <td id=\"T_b44a5_row8_col7\" class=\"data row8 col7\" >200</td>\n",
              "      <td id=\"T_b44a5_row8_col8\" class=\"data row8 col8\" >10</td>\n",
              "      <td id=\"T_b44a5_row8_col9\" class=\"data row8 col9\" >0.015758</td>\n",
              "      <td id=\"T_b44a5_row8_col10\" class=\"data row8 col10\" >0.036474</td>\n",
              "      <td id=\"T_b44a5_row8_col11\" class=\"data row8 col11\" >0.021127</td>\n",
              "      <td id=\"T_b44a5_row8_col12\" class=\"data row8 col12\" >0.038850</td>\n",
              "      <td id=\"T_b44a5_row8_col13\" class=\"data row8 col13\" >0.025429</td>\n",
              "      <td id=\"T_b44a5_row8_col14\" class=\"data row8 col14\" >0.036970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXyfgyKCsy2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}